{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Tandoor Recipes The recipe manager that allows you to manage your ever growing collection of digital recipes. Website \u2022 Installation \u2022 Docs \u2022 Demo \u2022 Discord Core Features \ud83e\udd57 Manage your recipes with a fast and intuitive editor \ud83d\udcc6 Plan multiple meals for each day \ud83d\uded2 Shopping lists via the meal plan or straight from recipes \ud83d\udcda Cookbooks collect recipes into books \ud83d\udc6a Share and collaborate on recipes with friends and family Made by and for power users \ud83d\udd0d Powerful & customizable search with fulltext support and TrigramSimilarity \ud83c\udff7\ufe0f Create and search for tags , assign them in batch to all files matching certain filters \u2194\ufe0f Quickly merge and rename ingredients, tags and units \ud83d\udce5\ufe0f Import recipes from thousands of websites supporting ld+json or microdata \u2797 Support for fractions or decimals \ud83d\udc33 Easy setup with Docker and included examples for Kubernetes , Unraid and Synology \ud83c\udfa8 Customize your interface with themes \ud83d\udce6 Sync files with Dropbox and Nextcloud All the must haves \ud83d\udcf1 Optimized for use on mobile devices \ud83c\udf0d Localized in many languages thanks to the awesome community \ud83d\udce5\ufe0f Import your collection from many other recipe managers \u2795 Many more like recipe scaling, image compression, printing views and supermarkets This application is meant for people with a collection of recipes they want to share with family and friends or simply store them in a nicely organized way. A basic permission system exists but this application is not meant to be run as a public page. Your Feedback Share some information on how you use Tandoor to help me improve the application Google Survey Get in touch Discord We have a public Discord server that anyone can join. This is where all our developers and contributors hang out and where we make announcements Twitter You can follow our Twitter account to get updates on new features or releases Roadmap This application has been under rapid development over the last year. During this time I have learnt a lot and added tons of features, I have also moved to some new technologies like Vue.js. This has led to some great features but has left the Quality unsatisfactory in regard to the details and technical implementation. So in addition to the new Features and Ideas which can always be found in the Issues & Milestones there are some greater overall goals for the future (in no particular order) Improve the UI! The Design is inconsistent and many pages work but don't look great. This needs to change. I strongly believe in Open Data and Systems. Thus adding importers and exporters for all relevant other recipe management systems is something i really want to do. Move all Javascript Libraries to a packet manager and clean up some of the mess I made in the early days Improve Test coverage and also the individual tests themselves Improve the documentation for all features and aspects of this project and add some application integrated help About This application has originally been developed to index, tag and search my collection of digital (PDF) recipes. Over the time tons of features have been added making this the most comprehensive recipe management system. I am just a single developer with many other interests and obligations so development and support might be slow at times, but I try my best to constantly improve this application. If you have any wishes, feature requests, problems or ideas feel free to open an issue on GitHub.","title":"Home"},{"location":"#core-features","text":"\ud83e\udd57 Manage your recipes with a fast and intuitive editor \ud83d\udcc6 Plan multiple meals for each day \ud83d\uded2 Shopping lists via the meal plan or straight from recipes \ud83d\udcda Cookbooks collect recipes into books \ud83d\udc6a Share and collaborate on recipes with friends and family","title":"Core Features"},{"location":"#made-by-and-for-power-users","text":"\ud83d\udd0d Powerful & customizable search with fulltext support and TrigramSimilarity \ud83c\udff7\ufe0f Create and search for tags , assign them in batch to all files matching certain filters \u2194\ufe0f Quickly merge and rename ingredients, tags and units \ud83d\udce5\ufe0f Import recipes from thousands of websites supporting ld+json or microdata \u2797 Support for fractions or decimals \ud83d\udc33 Easy setup with Docker and included examples for Kubernetes , Unraid and Synology \ud83c\udfa8 Customize your interface with themes \ud83d\udce6 Sync files with Dropbox and Nextcloud","title":"Made by and for power users"},{"location":"#all-the-must-haves","text":"\ud83d\udcf1 Optimized for use on mobile devices \ud83c\udf0d Localized in many languages thanks to the awesome community \ud83d\udce5\ufe0f Import your collection from many other recipe managers \u2795 Many more like recipe scaling, image compression, printing views and supermarkets This application is meant for people with a collection of recipes they want to share with family and friends or simply store them in a nicely organized way. A basic permission system exists but this application is not meant to be run as a public page.","title":"All the must haves"},{"location":"#your-feedback","text":"Share some information on how you use Tandoor to help me improve the application Google Survey","title":"Your Feedback"},{"location":"#get-in-touch","text":"Discord We have a public Discord server that anyone can join. This is where all our developers and contributors hang out and where we make announcements Twitter You can follow our Twitter account to get updates on new features or releases","title":"Get in touch"},{"location":"#roadmap","text":"This application has been under rapid development over the last year. During this time I have learnt a lot and added tons of features, I have also moved to some new technologies like Vue.js. This has led to some great features but has left the Quality unsatisfactory in regard to the details and technical implementation. So in addition to the new Features and Ideas which can always be found in the Issues & Milestones there are some greater overall goals for the future (in no particular order) Improve the UI! The Design is inconsistent and many pages work but don't look great. This needs to change. I strongly believe in Open Data and Systems. Thus adding importers and exporters for all relevant other recipe management systems is something i really want to do. Move all Javascript Libraries to a packet manager and clean up some of the mess I made in the early days Improve Test coverage and also the individual tests themselves Improve the documentation for all features and aspects of this project and add some application integrated help","title":"Roadmap"},{"location":"#about","text":"This application has originally been developed to index, tag and search my collection of digital (PDF) recipes. Over the time tons of features have been added making this the most comprehensive recipe management system. I am just a single developer with many other interests and obligations so development and support might be slow at times, but I try my best to constantly improve this application. If you have any wishes, feature requests, problems or ideas feel free to open an issue on GitHub.","title":"About"},{"location":"contribute/","text":"If you like this application and want it to improve, feel free to contribute to its development. Contribution List If you help bring this project forward you deserve to be credited for it. Feel free to add yourself to CONTRIBUTERS.md or message me to add you if you have contributed anything. Issues The most basic but also very important way of contributing is reporting issues and commenting on ideas and feature requests over at GitHub issues . Without feedback improvement can't happen, so don't hesitate to say what you want to say. Contributing Code If you want to contribute bug fixes or small tweaks then your pull requests are always welcome! Discuss First! If you want to contribute larger features that introduce more complexity to the project please make sure to first submit a technical description outlining what and how you want to do it. This allows me and the community to give feedback and manage the complexity of the overall application. If you don't do this please don't be mad if I reject your PR Info The dev setup is a little messy as this application combines the best (at least in my opinion) of both Django and Vue.js. Django This application is developed using the Django framework for Python. They have excellent documentation on how to get started, so I will only give you the basics here. Clone this repository wherever you like and install the Python language for your OS (I recommend using version 3.10 or above). Open it in your favorite editor/IDE (e.g. PyCharm). a. If you want, create a virtual environment for all your packages. Install all required packages: pip install -r requirements.txt . Run the migrations: python manage.py migrate . Start the development server: python manage.py runserver . There is no need to set any environment variables. By default, a simple SQLite database is used and all settings are populated from default values. Vue.js Most new frontend pages are build using Vue.js . In order to work on these pages, you will have to install a Javascript package manager of your choice. The following examples use yarn. Run yarn install to install the dependencies. After that you can use yarn serve to start the development server, and proceed to test your changes. If you do not wish to work on those pages, but instead want the application to work properly during development, run yarn build to build the frontend pages once. API Client The API Client is generated automatically from the OpenAPI interface provided by the Django REST framework. For this openapi-generator is used. Install it using your desired setup method. (For example, using npm install @openapitools/openapi-generator-cli -g .) Navigate to vue/src/utils/openapi . Generate the schema using openapi-generator-cli generate -g typescript-axios -i http://127.0.0.1:8000/openapi/ . (Replace your dev server url if required.) Contribute Documentation The documentation is built from the markdown files in the docs folder of the GitHub repository. In order to contribute to the documentation, you can fork the repository and edit the markdown files in the browser. Now install mkdocs and dependencies: pip install mkdocs-material mkdocs-include-markdown-plugin . If you want to test the documentation, locally run mkdocs serve from the project root. Contribute Translations If you know any foreign languages that the project has not been completely translated to yet, feel free to contribute translations. Translations are managed on translate.tandoor.dev , a self hosted instance of Weblate . You can simply register an account and then follow these steps to add translations: After registering, you are asked to select your languages. This is optional but allows weblate to only show you relevant translations. In the navigation click on Projects and then Browse all projects . Select Tandoor and on the top-right hand corner, select Watch project Tandoor (click on Not watching ). Go back to the dashboard. It now shows you the relevant translations for your languages. Click on the pencil icon to get started. Creating a new language To create a new language you must first select Tandoor (the project) and then a component. Here you will have the option to add the language. Afterwards you can also simply add it to the other components as well. Once a new language is (partially) finished let me know on GitHub so I can add it to the language-switcher in Tandoor itself. There is also a lot of documentation available from Weblate directly. It is also possible to provide the translations directly by creating a new language using manage.py makemessages -l <language_code> -i venv . Once finished, simply open a PR with the changed files. This sometimes causes issues merging with weblate, so I would prefer the use of weblate.","title":"Contributing"},{"location":"contribute/#issues","text":"The most basic but also very important way of contributing is reporting issues and commenting on ideas and feature requests over at GitHub issues . Without feedback improvement can't happen, so don't hesitate to say what you want to say.","title":"Issues"},{"location":"contribute/#contributing-code","text":"If you want to contribute bug fixes or small tweaks then your pull requests are always welcome! Discuss First! If you want to contribute larger features that introduce more complexity to the project please make sure to first submit a technical description outlining what and how you want to do it. This allows me and the community to give feedback and manage the complexity of the overall application. If you don't do this please don't be mad if I reject your PR Info The dev setup is a little messy as this application combines the best (at least in my opinion) of both Django and Vue.js.","title":"Contributing Code"},{"location":"contribute/#django","text":"This application is developed using the Django framework for Python. They have excellent documentation on how to get started, so I will only give you the basics here. Clone this repository wherever you like and install the Python language for your OS (I recommend using version 3.10 or above). Open it in your favorite editor/IDE (e.g. PyCharm). a. If you want, create a virtual environment for all your packages. Install all required packages: pip install -r requirements.txt . Run the migrations: python manage.py migrate . Start the development server: python manage.py runserver . There is no need to set any environment variables. By default, a simple SQLite database is used and all settings are populated from default values.","title":"Django"},{"location":"contribute/#vuejs","text":"Most new frontend pages are build using Vue.js . In order to work on these pages, you will have to install a Javascript package manager of your choice. The following examples use yarn. Run yarn install to install the dependencies. After that you can use yarn serve to start the development server, and proceed to test your changes. If you do not wish to work on those pages, but instead want the application to work properly during development, run yarn build to build the frontend pages once.","title":"Vue.js"},{"location":"contribute/#api-client","text":"The API Client is generated automatically from the OpenAPI interface provided by the Django REST framework. For this openapi-generator is used. Install it using your desired setup method. (For example, using npm install @openapitools/openapi-generator-cli -g .) Navigate to vue/src/utils/openapi . Generate the schema using openapi-generator-cli generate -g typescript-axios -i http://127.0.0.1:8000/openapi/ . (Replace your dev server url if required.)","title":"API Client"},{"location":"contribute/#contribute-documentation","text":"The documentation is built from the markdown files in the docs folder of the GitHub repository. In order to contribute to the documentation, you can fork the repository and edit the markdown files in the browser. Now install mkdocs and dependencies: pip install mkdocs-material mkdocs-include-markdown-plugin . If you want to test the documentation, locally run mkdocs serve from the project root.","title":"Contribute Documentation"},{"location":"contribute/#contribute-translations","text":"If you know any foreign languages that the project has not been completely translated to yet, feel free to contribute translations. Translations are managed on translate.tandoor.dev , a self hosted instance of Weblate . You can simply register an account and then follow these steps to add translations: After registering, you are asked to select your languages. This is optional but allows weblate to only show you relevant translations. In the navigation click on Projects and then Browse all projects . Select Tandoor and on the top-right hand corner, select Watch project Tandoor (click on Not watching ). Go back to the dashboard. It now shows you the relevant translations for your languages. Click on the pencil icon to get started. Creating a new language To create a new language you must first select Tandoor (the project) and then a component. Here you will have the option to add the language. Afterwards you can also simply add it to the other components as well. Once a new language is (partially) finished let me know on GitHub so I can add it to the language-switcher in Tandoor itself. There is also a lot of documentation available from Weblate directly. It is also possible to provide the translations directly by creating a new language using manage.py makemessages -l <language_code> -i venv . Once finished, simply open a PR with the changed files. This sometimes causes issues merging with weblate, so I would prefer the use of weblate.","title":"Contribute Translations"},{"location":"faq/","text":"There are several questions and issues that come up from time to time. Here are some answers. Please note that the existence of some questions is due the application not being perfect in some parts. Many of those shortcomings are planned to be fixed in future release but simply could not be addressed yet due to time limits. Is there a Tandoor app? Tandoor can be installed as a progressive web app (PWA) on mobile and desktop devices. The PWA stores recently accessed recipes locally for offline use. Mobile browsers Safari (iPhone/iPad) Open Tandoor, click Safari's share button, select Add to Home Screen Chrome/Chromium Open Tandoor, click the add Tandoor to the home screen message that pops up at the bottom of the screen Desktop browsers Google Chrome Open Tandoor, open the menu behind the three vertical dots at the top right, select Install Tandoor Recipes... Microsoft Edge Open Tandoor, open the menu behind the three horizontal dots at the top right, select Apps > Install Tandoor Recipes Why is Tandoor not working correctly? If you just set up your Tandoor instance and you're having issues like... Links not working CSRF errors CORS errors No recipes are loading ... then make sure, that you have set all required headers in your reverse proxy correctly. If that doesn't fix it, you can also refer to the appropriate sub section in the reverse proxy documentation and verify your general webserver configuration. Why am I getting CSRF Errors? If you are getting CSRF Errors this is most likely due to a reverse proxy not passing the correct headers. If you are using swag by linuxserver you might need proxy_set_header X-Forwarded-Proto $scheme; in your nginx config. If you are using a plain ngix you might need proxy_set_header Host $http_host; . Further discussions can be found in this Issue #518 Why are images not loading? If images are not loading this might be related to the same issue as the CSRF errors (see above). A discussion about that can be found at Issue #452 The other common issue is that the recommended nginx container is removed from the deployment stack. If removed, the nginx webserver needs to be replaced by something else that servers the /mediafiles/ directory or GUNICORN_MEDIA needs to be enabled to allow media serving by the application container itself. Why does the Text/Markdown preview look different than the final recipe ? Tandoor has always rendered the recipe instructions markdown on the server. This also allows tandoor to implement things like ingredient templating and scaling in text. To make editing easier a markdown editor was added to the frontend with integrated preview as a temporary solution. Since the markdown editor uses a different specification than the server the preview is different to the final result. It is planned to improve this in the future. The markdown renderer follows this markdown specification https://daringfireball.net/projects/markdown/ Why is Tandoor not working on my Raspberry Pi? Please refer to here . How can I create users? To create a new user click on your name (top right corner) and select 'space settings'. There under invites click create. It is not possible to create users through the admin because users must be assigned a default group and space. To change a users space you need to go to the admin and select User Infos. If you use an external auth provider or proxy authentication make sure to specify a default group and space in the environment configuration. What are spaces? Spaces are a feature used to separate one installation of Tandoor into several parts. In technical terms it is a multi tenant system. You can compare a space to something like google drive or dropbox. There is only one installation of the Dropbox system, but it handles multiple users without them noticing each other. For Tandoor that means all people that work together on one recipe collection can be in one space. If you want to host the collection of your friends family or your neighbor you can create a separate space for them (through the admin interface). Sharing between spaces is currently not possible but is planned for future releases. How can I reset passwords? To reset a lost password if access to the container is lost you need to execute into the container using docker-compose exec web_recipes sh activate the virtual environment source venv/bin/activate run python manage.py changepassword <username> and follow the steps shown. How can I add an admin user? To create a superuser you need to execute into the container using docker-compose exec web_recipes sh activate the virtual environment source venv/bin/activate run python manage.py createsuperuser and follow the steps shown.","title":"FAQ"},{"location":"faq/#is-there-a-tandoor-app","text":"Tandoor can be installed as a progressive web app (PWA) on mobile and desktop devices. The PWA stores recently accessed recipes locally for offline use.","title":"Is there a Tandoor app?"},{"location":"faq/#mobile-browsers","text":"","title":"Mobile browsers"},{"location":"faq/#safari-iphoneipad","text":"Open Tandoor, click Safari's share button, select Add to Home Screen","title":"Safari (iPhone/iPad)"},{"location":"faq/#chromechromium","text":"Open Tandoor, click the add Tandoor to the home screen message that pops up at the bottom of the screen","title":"Chrome/Chromium"},{"location":"faq/#desktop-browsers","text":"","title":"Desktop browsers"},{"location":"faq/#google-chrome","text":"Open Tandoor, open the menu behind the three vertical dots at the top right, select Install Tandoor Recipes...","title":"Google Chrome"},{"location":"faq/#microsoft-edge","text":"Open Tandoor, open the menu behind the three horizontal dots at the top right, select Apps > Install Tandoor Recipes","title":"Microsoft Edge"},{"location":"faq/#why-is-tandoor-not-working-correctly","text":"If you just set up your Tandoor instance and you're having issues like... Links not working CSRF errors CORS errors No recipes are loading ... then make sure, that you have set all required headers in your reverse proxy correctly. If that doesn't fix it, you can also refer to the appropriate sub section in the reverse proxy documentation and verify your general webserver configuration.","title":"Why is Tandoor not working correctly?"},{"location":"faq/#why-am-i-getting-csrf-errors","text":"If you are getting CSRF Errors this is most likely due to a reverse proxy not passing the correct headers. If you are using swag by linuxserver you might need proxy_set_header X-Forwarded-Proto $scheme; in your nginx config. If you are using a plain ngix you might need proxy_set_header Host $http_host; . Further discussions can be found in this Issue #518","title":"Why am I getting CSRF Errors?"},{"location":"faq/#why-are-images-not-loading","text":"If images are not loading this might be related to the same issue as the CSRF errors (see above). A discussion about that can be found at Issue #452 The other common issue is that the recommended nginx container is removed from the deployment stack. If removed, the nginx webserver needs to be replaced by something else that servers the /mediafiles/ directory or GUNICORN_MEDIA needs to be enabled to allow media serving by the application container itself.","title":"Why are images not loading?"},{"location":"faq/#why-does-the-textmarkdown-preview-look-different-than-the-final-recipe","text":"Tandoor has always rendered the recipe instructions markdown on the server. This also allows tandoor to implement things like ingredient templating and scaling in text. To make editing easier a markdown editor was added to the frontend with integrated preview as a temporary solution. Since the markdown editor uses a different specification than the server the preview is different to the final result. It is planned to improve this in the future. The markdown renderer follows this markdown specification https://daringfireball.net/projects/markdown/","title":"Why does the Text/Markdown preview look different than the final recipe ?"},{"location":"faq/#why-is-tandoor-not-working-on-my-raspberry-pi","text":"Please refer to here .","title":"Why is Tandoor not working on my Raspberry Pi?"},{"location":"faq/#how-can-i-create-users","text":"To create a new user click on your name (top right corner) and select 'space settings'. There under invites click create. It is not possible to create users through the admin because users must be assigned a default group and space. To change a users space you need to go to the admin and select User Infos. If you use an external auth provider or proxy authentication make sure to specify a default group and space in the environment configuration.","title":"How can I create users?"},{"location":"faq/#what-are-spaces","text":"Spaces are a feature used to separate one installation of Tandoor into several parts. In technical terms it is a multi tenant system. You can compare a space to something like google drive or dropbox. There is only one installation of the Dropbox system, but it handles multiple users without them noticing each other. For Tandoor that means all people that work together on one recipe collection can be in one space. If you want to host the collection of your friends family or your neighbor you can create a separate space for them (through the admin interface). Sharing between spaces is currently not possible but is planned for future releases.","title":"What are spaces?"},{"location":"faq/#how-can-i-reset-passwords","text":"To reset a lost password if access to the container is lost you need to execute into the container using docker-compose exec web_recipes sh activate the virtual environment source venv/bin/activate run python manage.py changepassword <username> and follow the steps shown.","title":"How can I reset passwords?"},{"location":"faq/#how-can-i-add-an-admin-user","text":"To create a superuser you need to execute into the container using docker-compose exec web_recipes sh activate the virtual environment source venv/bin/activate run python manage.py createsuperuser and follow the steps shown.","title":"How can I add an admin user?"},{"location":"features/authentication/","text":"Besides the normal django username and password authentication this application supports multiple methods of central account management and authentication. Allauth Django Allauth is an awesome project that allows you to use a huge number of different authentication providers. They basically explain everything in their documentation, but the following is a short overview on how to get started. Public Providers If you choose Google, Github or any other publicly available service as your authentication provider anyone with an account on that site can create an account on your installation. A new account does not have any permission but it is still not recommended to give public access to your installation. Choose a provider from the list and install it using the environment variable SOCIAL_PROVIDERS as shown in the example below. SOCIAL_PROVIDERS = allauth.socialaccount.providers.github,allauth.socialaccount.providers.nextcloud Formatting The exact formatting is important so make sure to follow the steps explained here! Depending on your authentication provider you might need to configure it. This needs to be done through the settings system. To make the system flexible (allow multiple providers) and to not require another file to be mounted into the container the configuration ins done through a single environment variable. The downside of this approach is that the configuration needs to be put into a single line as environment files loaded by docker compose don't support multiple lines for a single variable. Take the example configuration from the allauth docs, fill in your settings and then inline the whole object (you can use a service like www.freeformatter.com for formatting). Assign it to the additional SOCIALACCOUNT_PROVIDERS variable. SOCIALACCOUNT_PROVIDERS = {\"nextcloud\":{\"SERVER\":\"https://nextcloud.example.org\"}} Improvements ? There are most likely ways to achieve the same goal but with a cleaner or simpler system. If you know such a way feel free to let me know. After that, use your superuser account to configure your authentication backend. Open the admin page and do the following Select Sites and edit the default site with the URL of your installation (or create a new). Create a new Social Application with the required information as stated in the provider documentation of allauth. Make sure to add your site to the list of available sites Now the provider is configured and you should be able to sign up and sign in using the provider. Use the superuser account to grant permissions to the newly created users. WIP I do not have a ton of experience with using various single signon providers and also cannot test all of them. If you have any Feedback or issues let me know. Third-party authentication example Keycloak is a popular IAM solution and integration is straight forward thanks to Django Allauth. This example can also be used as reference for other third-party authentication solutions, as documented by Allauth. At Keycloak, create a new client and assign a Client-ID , this client comes with a Secret-Key . Both values are required later on. Make sure to define the correct Redirection-URL for the service, for example https://tandoor.example.com/* . Depending on your Keycloak setup, you need to assign roles and groups to grant access to the service. To enable Keycloak as a sign in option, set those variables to define the social provider and specify its configuration: SOCIAL_PROVIDERS = allauth.socialaccount.providers.keycloak SOCIALACCOUNT_PROVIDERS = '{ \"keycloak\": { \"KEYCLOAK_URL\": \"https://auth.example.com/\", \"KEYCLOAK_REALM\": \"master\" } }' Restart the service, login as superuser and open the Admin page. Make sure that the correct Domain Name is defined at Sites . Select Social Application and chose Keycloak from the provider list. Provide an arbitrary name for your authentication provider, and enter the Client-ID and Secret Key values obtained from Keycloak earlier. Make sure to add your Site to the list of available sites and save the new Social Application . You are now able to sign in using Keycloak. Linking accounts To link an account to an already existing normal user go to the settings page of the user and link it. Here you can also unlink your account if you no longer want to use a social login method. LDAP LDAP authentication can be enabled in the .env file by setting LDAP_AUTH=1 . If set, users listed in the LDAP instance will be able to sign in without signing up. These variables must be set to configure the connection to the LDAP instance: AUTH_LDAP_SERVER_URI=ldap://ldap.example.org:389 AUTH_LDAP_BIND_DN=uid=admin,ou=users,dc=example,dc=org AUTH_LDAP_BIND_PASSWORD=adminpassword AUTH_LDAP_USER_SEARCH_BASE_DN=ou=users,dc=example,dc=org Additional optional variables: AUTH_LDAP_USER_SEARCH_FILTER_STR=(uid=%(user)s) AUTH_LDAP_USER_ATTR_MAP={'first_name': 'givenName', 'last_name': 'sn', 'email': 'mail'} AUTH_LDAP_ALWAYS_UPDATE_USER=1 AUTH_LDAP_CACHE_TIMEOUT=3600 AUTH_LDAP_TLS_CACERTFILE=/etc/ssl/certs/own-ca.pem Reverse Proxy Authentication Community Contributed Tutorial This tutorial was provided by a community member. Since I do not use reverse proxy authentication, I cannot provide any assistance should you choose to use this authentication method. In order use proxy authentication you will need to: Set REVERSE_PROXY_AUTH=1 in the .env file Update your nginx configuration file Using any of the examples above will automatically generate a configuration file inside a docker volume. Use docker volume inspect recipes_nginx to find out where your volume is stored. Configuration File Volume The nginx config volume is generated when the container is first run. You can change the volume to a bind mount in the warning docker-compose.yml , but then you will need to manually create it. See section Volumes vs Bind Mounts below for more information. The following example shows a configuration for Authelia: server { listen 80; server_name localhost; client_max_body_size 16M; # serve static files location /static/ { alias /static/; } # serve media files location /media/ { alias /media/; } # Authelia endpoint for authentication requests include /config/nginx/auth.conf; # pass requests for dynamic content to gunicorn location / { proxy_set_header Host $host; proxy_pass http://web_recipes:8080; # Ensure Authelia is specifically required for this endpoint # This line is important as it will return a 401 error if the user doesn't have access include /config/nginx/authelia.conf; auth_request_set $user $upstream_http_remote_user; proxy_set_header REMOTE-USER $user; } # Required to allow user to logout of authentication from within Recipes # Ensure the <auth_endpoint> below is changed to actual the authentication url location /accounts/logout/ { return 301 http://<auth_endpoint>/logout; } } Please refer to the appropriate documentation on how to setup the reverse proxy, authentication, and networks. Ensure users have been configured for Authelia, and that the endpoint recipes is pointed to is protected but available. There is a good guide to the other additional files that need to be added to your nginx set up at the Authelia Docs . Remember to add the appropriate environment variables to .env file (example for nginx proxy): VIRTUAL_HOST= LETSENCRYPT_HOST= LETSENCRYPT_EMAIL= PROXY_HEADER=","title":"Authentication"},{"location":"features/authentication/#allauth","text":"Django Allauth is an awesome project that allows you to use a huge number of different authentication providers. They basically explain everything in their documentation, but the following is a short overview on how to get started. Public Providers If you choose Google, Github or any other publicly available service as your authentication provider anyone with an account on that site can create an account on your installation. A new account does not have any permission but it is still not recommended to give public access to your installation. Choose a provider from the list and install it using the environment variable SOCIAL_PROVIDERS as shown in the example below. SOCIAL_PROVIDERS = allauth.socialaccount.providers.github,allauth.socialaccount.providers.nextcloud Formatting The exact formatting is important so make sure to follow the steps explained here! Depending on your authentication provider you might need to configure it. This needs to be done through the settings system. To make the system flexible (allow multiple providers) and to not require another file to be mounted into the container the configuration ins done through a single environment variable. The downside of this approach is that the configuration needs to be put into a single line as environment files loaded by docker compose don't support multiple lines for a single variable. Take the example configuration from the allauth docs, fill in your settings and then inline the whole object (you can use a service like www.freeformatter.com for formatting). Assign it to the additional SOCIALACCOUNT_PROVIDERS variable. SOCIALACCOUNT_PROVIDERS = {\"nextcloud\":{\"SERVER\":\"https://nextcloud.example.org\"}} Improvements ? There are most likely ways to achieve the same goal but with a cleaner or simpler system. If you know such a way feel free to let me know. After that, use your superuser account to configure your authentication backend. Open the admin page and do the following Select Sites and edit the default site with the URL of your installation (or create a new). Create a new Social Application with the required information as stated in the provider documentation of allauth. Make sure to add your site to the list of available sites Now the provider is configured and you should be able to sign up and sign in using the provider. Use the superuser account to grant permissions to the newly created users. WIP I do not have a ton of experience with using various single signon providers and also cannot test all of them. If you have any Feedback or issues let me know.","title":"Allauth"},{"location":"features/authentication/#third-party-authentication-example","text":"Keycloak is a popular IAM solution and integration is straight forward thanks to Django Allauth. This example can also be used as reference for other third-party authentication solutions, as documented by Allauth. At Keycloak, create a new client and assign a Client-ID , this client comes with a Secret-Key . Both values are required later on. Make sure to define the correct Redirection-URL for the service, for example https://tandoor.example.com/* . Depending on your Keycloak setup, you need to assign roles and groups to grant access to the service. To enable Keycloak as a sign in option, set those variables to define the social provider and specify its configuration: SOCIAL_PROVIDERS = allauth.socialaccount.providers.keycloak SOCIALACCOUNT_PROVIDERS = '{ \"keycloak\": { \"KEYCLOAK_URL\": \"https://auth.example.com/\", \"KEYCLOAK_REALM\": \"master\" } }' Restart the service, login as superuser and open the Admin page. Make sure that the correct Domain Name is defined at Sites . Select Social Application and chose Keycloak from the provider list. Provide an arbitrary name for your authentication provider, and enter the Client-ID and Secret Key values obtained from Keycloak earlier. Make sure to add your Site to the list of available sites and save the new Social Application . You are now able to sign in using Keycloak.","title":"Third-party authentication example"},{"location":"features/authentication/#linking-accounts","text":"To link an account to an already existing normal user go to the settings page of the user and link it. Here you can also unlink your account if you no longer want to use a social login method.","title":"Linking accounts"},{"location":"features/authentication/#ldap","text":"LDAP authentication can be enabled in the .env file by setting LDAP_AUTH=1 . If set, users listed in the LDAP instance will be able to sign in without signing up. These variables must be set to configure the connection to the LDAP instance: AUTH_LDAP_SERVER_URI=ldap://ldap.example.org:389 AUTH_LDAP_BIND_DN=uid=admin,ou=users,dc=example,dc=org AUTH_LDAP_BIND_PASSWORD=adminpassword AUTH_LDAP_USER_SEARCH_BASE_DN=ou=users,dc=example,dc=org Additional optional variables: AUTH_LDAP_USER_SEARCH_FILTER_STR=(uid=%(user)s) AUTH_LDAP_USER_ATTR_MAP={'first_name': 'givenName', 'last_name': 'sn', 'email': 'mail'} AUTH_LDAP_ALWAYS_UPDATE_USER=1 AUTH_LDAP_CACHE_TIMEOUT=3600 AUTH_LDAP_TLS_CACERTFILE=/etc/ssl/certs/own-ca.pem","title":"LDAP"},{"location":"features/authentication/#reverse-proxy-authentication","text":"Community Contributed Tutorial This tutorial was provided by a community member. Since I do not use reverse proxy authentication, I cannot provide any assistance should you choose to use this authentication method. In order use proxy authentication you will need to: Set REVERSE_PROXY_AUTH=1 in the .env file Update your nginx configuration file Using any of the examples above will automatically generate a configuration file inside a docker volume. Use docker volume inspect recipes_nginx to find out where your volume is stored. Configuration File Volume The nginx config volume is generated when the container is first run. You can change the volume to a bind mount in the warning docker-compose.yml , but then you will need to manually create it. See section Volumes vs Bind Mounts below for more information. The following example shows a configuration for Authelia: server { listen 80; server_name localhost; client_max_body_size 16M; # serve static files location /static/ { alias /static/; } # serve media files location /media/ { alias /media/; } # Authelia endpoint for authentication requests include /config/nginx/auth.conf; # pass requests for dynamic content to gunicorn location / { proxy_set_header Host $host; proxy_pass http://web_recipes:8080; # Ensure Authelia is specifically required for this endpoint # This line is important as it will return a 401 error if the user doesn't have access include /config/nginx/authelia.conf; auth_request_set $user $upstream_http_remote_user; proxy_set_header REMOTE-USER $user; } # Required to allow user to logout of authentication from within Recipes # Ensure the <auth_endpoint> below is changed to actual the authentication url location /accounts/logout/ { return 301 http://<auth_endpoint>/logout; } } Please refer to the appropriate documentation on how to setup the reverse proxy, authentication, and networks. Ensure users have been configured for Authelia, and that the endpoint recipes is pointed to is protected but available. There is a good guide to the other additional files that need to be added to your nginx set up at the Authelia Docs . Remember to add the appropriate environment variables to .env file (example for nginx proxy): VIRTUAL_HOST= LETSENCRYPT_HOST= LETSENCRYPT_EMAIL= PROXY_HEADER=","title":"Reverse Proxy Authentication"},{"location":"features/external_recipes/","text":"The original intend of this application was to provide a search interface to my large collection of PDF scans of recipes. This feature is now called External recipes. Info Internal recipes are stored in a structured manner inside the database. They can be displayed using the standardized interface and support features like shopping lists, scaling and steps. External recipes are basically files that are displayed within the interface. The benefit is that you can quickly import all your old recipes and convert them one by one. To use external recipes you will first need to configure a storage source. After that a synced path can be created. Lastly you will need to sync with the external path and import recipes you desire. Storage Danger In order for this application to retrieve data from external providers it needs to store authentication information. Please use read only/separate accounts or app passwords wherever possible. There are better ways to do this but they are currently not implemented A Storage Backend is a remote storage location where files are read from. To add a new backend click on username >> External Recipes >> Manage External Storage >> the + next to Storage Backend List . There click the plus button. The basic configuration is the same for all providers. Field Value Name Your identifier for this storage source, can be everything you want. Method The desired method. Success Only the providers listed below are currently implemented. If you need anything else feel free to open an issue or pull request. Local Info There is currently no way to upload files through the webinterface. This is a feature that might be added later. The local provider does not need any configuration (username, password, token or URL). For the monitor you will need to define a valid path on your host system. (Path) The Path depends on your setup and can be both relative and absolute. Volume By default no data other than the mediafiles and the database is persisted. If you use the local provider make sure to mount the path you choose to monitor to your host system in order to keep it persistent. Docker If you use docker the default directory is /opt/recipes/ . add - ./externalfiles:/opt/recipes/externalfiles to your docker-compose.yml file under the web_recipes >> volumes section. This will create a folder in your docker directory named externalfiles under which you could choose to store external pdfs (you could of course store them anywhere, just change ./externalfiles to your preferred location). save the docker-compose.yml and restart your docker container. Dropbox Field Value Username Dropbox username Token Dropbox API Token. Can be found here Nextcloud Path It appears that the correct webdav path varies from installation to installation (for whatever reason). In the Nextcloud webinterface click the Settings button in the bottom left corner, there your WebDav Url will be displayed. Field Value Username Nextcloud username Password Nextcloud app password Url Nextcloud Server URL (e.g. https://cloud.mydomain.com ) Path (optional) webdav path (e.g. /remote.php/dav/files/vabene1111 ). If no path is supplied /remote.php/dav/files/ plus your username will be used. Adding External Recipes To add a new path from your Storage backend to the sync list, go to username >> External Recipes and select the storage backend you want to use. Then enter the path you want to monitor starting at the storage root (e.g. /Folder/RecipesFolder , or `/opt/recipes/externalfiles' in the docker example above) and save it. Syncing Data To sync the recipes app with the storage backends press Sync now under username >> External Recipes Discovered Recipes All files found by the sync can be found under Manage Data >> Discovered recipes . There you can either import all at once without modifying them or import one by one, adding tags while importing.","title":"Storages and Sync"},{"location":"features/external_recipes/#storage","text":"Danger In order for this application to retrieve data from external providers it needs to store authentication information. Please use read only/separate accounts or app passwords wherever possible. There are better ways to do this but they are currently not implemented A Storage Backend is a remote storage location where files are read from. To add a new backend click on username >> External Recipes >> Manage External Storage >> the + next to Storage Backend List . There click the plus button. The basic configuration is the same for all providers. Field Value Name Your identifier for this storage source, can be everything you want. Method The desired method. Success Only the providers listed below are currently implemented. If you need anything else feel free to open an issue or pull request.","title":"Storage"},{"location":"features/external_recipes/#local","text":"Info There is currently no way to upload files through the webinterface. This is a feature that might be added later. The local provider does not need any configuration (username, password, token or URL). For the monitor you will need to define a valid path on your host system. (Path) The Path depends on your setup and can be both relative and absolute. Volume By default no data other than the mediafiles and the database is persisted. If you use the local provider make sure to mount the path you choose to monitor to your host system in order to keep it persistent.","title":"Local"},{"location":"features/external_recipes/#docker","text":"If you use docker the default directory is /opt/recipes/ . add - ./externalfiles:/opt/recipes/externalfiles to your docker-compose.yml file under the web_recipes >> volumes section. This will create a folder in your docker directory named externalfiles under which you could choose to store external pdfs (you could of course store them anywhere, just change ./externalfiles to your preferred location). save the docker-compose.yml and restart your docker container.","title":"Docker"},{"location":"features/external_recipes/#dropbox","text":"Field Value Username Dropbox username Token Dropbox API Token. Can be found here","title":"Dropbox"},{"location":"features/external_recipes/#nextcloud","text":"Path It appears that the correct webdav path varies from installation to installation (for whatever reason). In the Nextcloud webinterface click the Settings button in the bottom left corner, there your WebDav Url will be displayed. Field Value Username Nextcloud username Password Nextcloud app password Url Nextcloud Server URL (e.g. https://cloud.mydomain.com ) Path (optional) webdav path (e.g. /remote.php/dav/files/vabene1111 ). If no path is supplied /remote.php/dav/files/ plus your username will be used.","title":"Nextcloud"},{"location":"features/external_recipes/#adding-external-recipes","text":"To add a new path from your Storage backend to the sync list, go to username >> External Recipes and select the storage backend you want to use. Then enter the path you want to monitor starting at the storage root (e.g. /Folder/RecipesFolder , or `/opt/recipes/externalfiles' in the docker example above) and save it.","title":"Adding External Recipes"},{"location":"features/external_recipes/#syncing-data","text":"To sync the recipes app with the storage backends press Sync now under username >> External Recipes","title":"Syncing Data"},{"location":"features/external_recipes/#discovered-recipes","text":"All files found by the sync can be found under Manage Data >> Discovered recipes . There you can either import all at once without modifying them or import one by one, adding tags while importing.","title":"Discovered Recipes"},{"location":"features/import_export/","text":"This application features a very versatile import and export feature in order to offer the best experience possible and allow you to freely choose where your data goes. WIP The Module is relatively new. There is a known issue with Timeouts on large exports. A fix is being developed and will likely be released with the next version. The Module is built with maximum flexibility and expandability in mind and allows to easily add new integrations to allow you to both import and export your recipes into whatever format you desire. Feel like there is an important integration missing? Just take a look at the integration issues or open a new one if your favorite one is missing. Export I strongly believe in everyone's right to use their data as they please and therefore want to give you the best possible flexibility with your recipes. That said for most of the people getting this application running with their recipes is the biggest priority. Because of this importing as many formats as possible is prioritized over exporting. Exporter for the different formats will follow over time. Overview of the capabilities of the different integrations. Integration Import Export Images Default \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f Nextcloud \u2714\ufe0f \u231a \u2714\ufe0f Mealie \u2714\ufe0f \u231a \u2714\ufe0f Chowdown \u2714\ufe0f \u231a \u2714\ufe0f Safron \u2714\ufe0f \u2714\ufe0f \u274c Paprika \u2714\ufe0f \u231a \u2714\ufe0f ChefTap \u2714\ufe0f \u274c \u274c Pepperplate \u2714\ufe0f \u231a \u274c RecipeSage \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f Domestica \u2714\ufe0f \u231a \u2714\ufe0f MealMaster \u2714\ufe0f \u274c \u274c RezKonv \u2714\ufe0f \u274c \u274c OpenEats \u2714\ufe0f \u274c \u231a Plantoeat \u2714\ufe0f \u274c \u2714 CookBookApp \u2714\ufe0f \u231a \u2714\ufe0f CopyMeThat \u2714\ufe0f \u274c \u2714\ufe0f Melarecipes \u2714\ufe0f \u231a \u2714\ufe0f Cookmate \u2714\ufe0f \u231a \u2714\ufe0f PDF (experimental) \u231a\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f = implemented, \u274c = not implemented and not possible/planned, \u231a = not yet implemented Default The default integration is the built in (and preferred) way to import and export recipes. It is maintained with new fields added and contains all data to transfer your recipes from one installation to another. It is also one of the few recipe formats that is actually structured in a way that allows for easy machine readability if you want to use the data for any other purpose. RecipeSage Go to Settings > Export Recipe Data and select EXPORT AS JSON-LD (BEST) . Then simply upload the exported file to Tandoor. The RecipeSage integration also allows exporting. To migrate from Tandoor to RecipeSage simply export with Recipe Sage selected and import the json file in RecipeSage. Images are currently not supported for exporting. Domestica Go to Import/Export and select Export Recipes . Then simply upload the exported file to Tandoor. Nextcloud Importing recipes from Nextcloud cookbook is very easy and since Nextcloud Cookbook provides nice, standardized and structured information most of your recipe is going to be intact. Follow these steps to import your recipes Go to your Nextcloud Webinterface Open the Recipes folder where your recipes are stored Select the recipes you want to export or use the checkbox at the top of the list to select all of them Click on the three dot Actions and press Download You will get a Recipes.zip file. Simply upload the file and choose the Nextcloud Cookbook type. Folder Structure Importing only works if the folder structure is correct. If you do not use the standard path or create the zip file in any other way make sure the structure is as follows Recipes.zip/ \u2514\u2500\u2500 Recipes/ \u251c\u2500\u2500 Recipe1/ \u2502 \u251c\u2500\u2500 recipe.json \u2502 \u2514\u2500\u2500 full.jpg \u2514\u2500\u2500 Recipe2/ \u251c\u2500\u2500 recipe.json \u2514\u2500\u2500 full.jpg Mealie Mealie provides structured data similar to nextcloud. To migrate your recipes Go to your Mealie settings and create a new Backup. Download the backup by clicking on it and pressing download (this wasn't working for me, so I had to manually pull it from the server). Upload the entire .zip file to the importer page and import everything. Chowdown Chowdown stores all your recipes in plain text markdown files in a directory called _recipes . Images are saved in a directory called images . In order to import your Chowdown recipes simply create a .zip file from those two folders and import them. The folder structure should look as follows _recipes For some reason chowdown uses _ before the recipes folder. To avoid confusion the import supports both _recipes and recipes Recipes.zip/ \u251c\u2500\u2500 _recipes/ \u2502 \u251c\u2500\u2500 recipe one.md \u2502 \u251c\u2500\u2500 recipe two.md \u2502 \u2514\u2500\u2500 ... \u2514\u2500\u2500 images/ \u251c\u2500\u2500 image-name.jpg \u251c\u2500\u2500 second-image-name.jpg \u2514\u2500\u2500 ... Safron Go to your safron settings page and export your recipes. Then simply upload the entire .zip file to the importer. Images Safron exports do not contain any images. They will be lost during import. Paprika A Paprika export contains a folder with a html representation of your recipes and a .paprikarecipes file. The .paprikarecipes file is basically just a zip with gzipped contents. Simply upload the whole file and import all your recipes. Pepperplate Pepperplate provides a .zip file containing all of your recipes as .txt files. These files are well-structured and allow the import of all data without losing anything. Simply export the recipes from Pepperplate and upload the zip to Tandoor. Images are not included in the export and thus cannot be imported. ChefTap ChefTaps allows you to export your recipes from the app (I think). The export is a zip file containing a folder called cheftap_export which in turn contains .txt files with your recipes. This format is basically completely unstructured and every export looks different. This makes importing it very hard and leads to suboptimal results. Images are also not supported as they are not included in the export (at least the tests I had). Usually the import should recognize all ingredients and put everything else into the instructions. If your import fails or is worse than this feel free to provide me with more example data and I can try to improve the importer. As ChefTap cannot import these files anyway there won't be an exporter implemented in Tandoor. MealMaster Meal master can be imported by uploading one or more meal master files. The files should either be .txt , .MMF or .MM files. The MealMaster spec allows for many variations. Currently, only the one column format for ingredients is supported. Second line notes to ingredients are currently also not imported as a note but simply put into the instructions. If you have MealMaster recipes that cannot be imported feel free to raise an issue. RezKonv The RezKonv format is primarily used in the german recipe manager RezKonv Suite. To migrate from RezKonv Suite to Tandoor select Export > Gesamtes Kochbuch exportieren (the last option in the export menu). The generated file can simply be imported into Tandoor. As I only had limited sample data feel free to open an issue if your RezKonv export cannot be imported. Recipekeeper Recipe keeper allows you to export a zip file containing recipes and images using its apps. This zip file can simply be imported into Tandoor. OpenEats OpenEats does not provide any way to export the data using the interface. Luckily it is relatively easy to export it from the command line. You need to run the command python manage.py dumpdata recipe ingredient inside of the application api container. If you followed the default installation method you can use the following command docker-compose -f docker-prod.yml run --rm --entrypoint 'sh' api ./manage.py dumpdata recipe ingredient . This command might also work docker exec -it openeats_api_1 ./manage.py dumpdata recipe ingredient > recipe_ingredients.json Store the outputted json string in a .json file and simply import it using the importer. The file should look something like this [ { \"model\" : \"recipe.recipe\" , \"pk\" : 1 , \"fields\" :{ \"title\" : \"Tasty Chili\" , ... } }, ... { \"model\" : \"ingredient.ingredientgroup\" , \"pk\" : 1 , \"fields\" :{ \"title\" : \"Veges\" , \"recipe\" : 1 } }, ... { \"model\" : \"ingredient.ingredient\" , \"pk\" : 1 , \"fields\" :{ \"title\" : \"black pepper\" , \"numerator\" : 1.0 , \"denominator\" : 1.0 , \"measurement\" : \"dash\" , \"ingredient_group\" : 1 } } ] Plantoeat Plan to eat allows you to export a text file containing all your recipes. Simply upload that text file to Tandoor to import all recipes CookBookApp CookBookApp can export .zip files containing .html files. Upload the entire ZIP to Tandoor to import all included recipes. CopyMeThat CopyMeThat can export .zip files containing an .html file as well as a folder containing all the images. Upload the entire ZIP to Tandoor to import all included recipes. Cookmate Cookmate allows you to export a .mcb file which you can simply upload to tandoor and import all your recipes. RecetteTek RecetteTek exports are .rtk files which can simply be uploaded to tandoor to import all your recipes. Melarecipes Melarecipes provides multiple export formats but only the MelaRecipes format can export the complete collection. Perform this export and open the .melarecipes file using your favorite archive opening program (e.g 7zip). Repeat this if the file contains another .melarecipes file until you get a list of one or many .melarecipe files. Upload all .melarecipe files you want to import to tandoor and start the import. PDF The PDF Exporter is an experimental feature that uses the puppeteer browser renderer to render each recipe and export it to PDF. For that to work it downloads a chromium binary of about 140 MB to your server and then renders the PDF files using that. Since that is something some server administrators might not want there the PDF exporter is disabled by default and can be enabled with ENABLE_PDF_EXPORT=1 in .env . See this issue for more discussion on this and this issue for the future plans to support server side rendering.","title":"Import/Export"},{"location":"features/import_export/#default","text":"The default integration is the built in (and preferred) way to import and export recipes. It is maintained with new fields added and contains all data to transfer your recipes from one installation to another. It is also one of the few recipe formats that is actually structured in a way that allows for easy machine readability if you want to use the data for any other purpose.","title":"Default"},{"location":"features/import_export/#recipesage","text":"Go to Settings > Export Recipe Data and select EXPORT AS JSON-LD (BEST) . Then simply upload the exported file to Tandoor. The RecipeSage integration also allows exporting. To migrate from Tandoor to RecipeSage simply export with Recipe Sage selected and import the json file in RecipeSage. Images are currently not supported for exporting.","title":"RecipeSage"},{"location":"features/import_export/#domestica","text":"Go to Import/Export and select Export Recipes . Then simply upload the exported file to Tandoor.","title":"Domestica"},{"location":"features/import_export/#nextcloud","text":"Importing recipes from Nextcloud cookbook is very easy and since Nextcloud Cookbook provides nice, standardized and structured information most of your recipe is going to be intact. Follow these steps to import your recipes Go to your Nextcloud Webinterface Open the Recipes folder where your recipes are stored Select the recipes you want to export or use the checkbox at the top of the list to select all of them Click on the three dot Actions and press Download You will get a Recipes.zip file. Simply upload the file and choose the Nextcloud Cookbook type. Folder Structure Importing only works if the folder structure is correct. If you do not use the standard path or create the zip file in any other way make sure the structure is as follows Recipes.zip/ \u2514\u2500\u2500 Recipes/ \u251c\u2500\u2500 Recipe1/ \u2502 \u251c\u2500\u2500 recipe.json \u2502 \u2514\u2500\u2500 full.jpg \u2514\u2500\u2500 Recipe2/ \u251c\u2500\u2500 recipe.json \u2514\u2500\u2500 full.jpg","title":"Nextcloud"},{"location":"features/import_export/#mealie","text":"Mealie provides structured data similar to nextcloud. To migrate your recipes Go to your Mealie settings and create a new Backup. Download the backup by clicking on it and pressing download (this wasn't working for me, so I had to manually pull it from the server). Upload the entire .zip file to the importer page and import everything.","title":"Mealie"},{"location":"features/import_export/#chowdown","text":"Chowdown stores all your recipes in plain text markdown files in a directory called _recipes . Images are saved in a directory called images . In order to import your Chowdown recipes simply create a .zip file from those two folders and import them. The folder structure should look as follows _recipes For some reason chowdown uses _ before the recipes folder. To avoid confusion the import supports both _recipes and recipes Recipes.zip/ \u251c\u2500\u2500 _recipes/ \u2502 \u251c\u2500\u2500 recipe one.md \u2502 \u251c\u2500\u2500 recipe two.md \u2502 \u2514\u2500\u2500 ... \u2514\u2500\u2500 images/ \u251c\u2500\u2500 image-name.jpg \u251c\u2500\u2500 second-image-name.jpg \u2514\u2500\u2500 ...","title":"Chowdown"},{"location":"features/import_export/#safron","text":"Go to your safron settings page and export your recipes. Then simply upload the entire .zip file to the importer. Images Safron exports do not contain any images. They will be lost during import.","title":"Safron"},{"location":"features/import_export/#paprika","text":"A Paprika export contains a folder with a html representation of your recipes and a .paprikarecipes file. The .paprikarecipes file is basically just a zip with gzipped contents. Simply upload the whole file and import all your recipes.","title":"Paprika"},{"location":"features/import_export/#pepperplate","text":"Pepperplate provides a .zip file containing all of your recipes as .txt files. These files are well-structured and allow the import of all data without losing anything. Simply export the recipes from Pepperplate and upload the zip to Tandoor. Images are not included in the export and thus cannot be imported.","title":"Pepperplate"},{"location":"features/import_export/#cheftap","text":"ChefTaps allows you to export your recipes from the app (I think). The export is a zip file containing a folder called cheftap_export which in turn contains .txt files with your recipes. This format is basically completely unstructured and every export looks different. This makes importing it very hard and leads to suboptimal results. Images are also not supported as they are not included in the export (at least the tests I had). Usually the import should recognize all ingredients and put everything else into the instructions. If your import fails or is worse than this feel free to provide me with more example data and I can try to improve the importer. As ChefTap cannot import these files anyway there won't be an exporter implemented in Tandoor.","title":"ChefTap"},{"location":"features/import_export/#mealmaster","text":"Meal master can be imported by uploading one or more meal master files. The files should either be .txt , .MMF or .MM files. The MealMaster spec allows for many variations. Currently, only the one column format for ingredients is supported. Second line notes to ingredients are currently also not imported as a note but simply put into the instructions. If you have MealMaster recipes that cannot be imported feel free to raise an issue.","title":"MealMaster"},{"location":"features/import_export/#rezkonv","text":"The RezKonv format is primarily used in the german recipe manager RezKonv Suite. To migrate from RezKonv Suite to Tandoor select Export > Gesamtes Kochbuch exportieren (the last option in the export menu). The generated file can simply be imported into Tandoor. As I only had limited sample data feel free to open an issue if your RezKonv export cannot be imported.","title":"RezKonv"},{"location":"features/import_export/#recipekeeper","text":"Recipe keeper allows you to export a zip file containing recipes and images using its apps. This zip file can simply be imported into Tandoor.","title":"Recipekeeper"},{"location":"features/import_export/#openeats","text":"OpenEats does not provide any way to export the data using the interface. Luckily it is relatively easy to export it from the command line. You need to run the command python manage.py dumpdata recipe ingredient inside of the application api container. If you followed the default installation method you can use the following command docker-compose -f docker-prod.yml run --rm --entrypoint 'sh' api ./manage.py dumpdata recipe ingredient . This command might also work docker exec -it openeats_api_1 ./manage.py dumpdata recipe ingredient > recipe_ingredients.json Store the outputted json string in a .json file and simply import it using the importer. The file should look something like this [ { \"model\" : \"recipe.recipe\" , \"pk\" : 1 , \"fields\" :{ \"title\" : \"Tasty Chili\" , ... } }, ... { \"model\" : \"ingredient.ingredientgroup\" , \"pk\" : 1 , \"fields\" :{ \"title\" : \"Veges\" , \"recipe\" : 1 } }, ... { \"model\" : \"ingredient.ingredient\" , \"pk\" : 1 , \"fields\" :{ \"title\" : \"black pepper\" , \"numerator\" : 1.0 , \"denominator\" : 1.0 , \"measurement\" : \"dash\" , \"ingredient_group\" : 1 } } ]","title":"OpenEats"},{"location":"features/import_export/#plantoeat","text":"Plan to eat allows you to export a text file containing all your recipes. Simply upload that text file to Tandoor to import all recipes","title":"Plantoeat"},{"location":"features/import_export/#cookbookapp","text":"CookBookApp can export .zip files containing .html files. Upload the entire ZIP to Tandoor to import all included recipes.","title":"CookBookApp"},{"location":"features/import_export/#copymethat","text":"CopyMeThat can export .zip files containing an .html file as well as a folder containing all the images. Upload the entire ZIP to Tandoor to import all included recipes.","title":"CopyMeThat"},{"location":"features/import_export/#cookmate","text":"Cookmate allows you to export a .mcb file which you can simply upload to tandoor and import all your recipes.","title":"Cookmate"},{"location":"features/import_export/#recettetek","text":"RecetteTek exports are .rtk files which can simply be uploaded to tandoor to import all your recipes.","title":"RecetteTek"},{"location":"features/import_export/#melarecipes","text":"Melarecipes provides multiple export formats but only the MelaRecipes format can export the complete collection. Perform this export and open the .melarecipes file using your favorite archive opening program (e.g 7zip). Repeat this if the file contains another .melarecipes file until you get a list of one or many .melarecipe files. Upload all .melarecipe files you want to import to tandoor and start the import.","title":"Melarecipes"},{"location":"features/import_export/#pdf","text":"The PDF Exporter is an experimental feature that uses the puppeteer browser renderer to render each recipe and export it to PDF. For that to work it downloads a chromium binary of about 140 MB to your server and then renders the PDF files using that. Since that is something some server administrators might not want there the PDF exporter is disabled by default and can be enabled with ENABLE_PDF_EXPORT=1 in .env . See this issue for more discussion on this and this issue for the future plans to support server side rendering.","title":"PDF"},{"location":"features/shopping/","text":"WIP While being around for a while there are still a lot of features that i plan on adding to the shopping list. You can see an overview of what is still planned on this issue. Shopping lists allow you to easily convert a recipe or even a whole meal plan into a shopping list. From there you can either use it on the site or export it to your shopping list of choice. It also includes automatic supermarket specific ordering. Create Shopping Lists You have three options to create a shopping list Open a recipe of your choice. From the context menu choose Add to Shoppinglist and create a new list with the recipe already added. After adding recipes to the meal plan you can click the little shopping cart icon to add the recipes to the shopping list. They will be shown below the plan, from there you can open a new shopping list with them. The last option is to open the shopping list page and click the little plus icon to create a new list. Supermarket Ordering WIP This feature is relatively new and I did not have the time to completely polished it yet, that said it already works quite well. You can create Supermarket Categories and Supermarkets in the admin interface. After setting this up you can choose a supermarket for each shopping list. This will automatically show the categories configured for this supermarket in the order specified. All Foods that are not yet categorized can be dragged into their category, this will save the categories for the future. Sharing & Autosync If you want to collaborate on the creation and usage of the shopping list you can add a user to the list of shared users. Each user now has access to the list and can edit it. When checking items in viewing mode the change is synced to all other clients that currently have the same list open. You can set the syncing interval in your user settings. Other Features There are a few more features worth pointing out You can export recipes for use in other applications (Google Keep, etc.) by using the export button In the export popup you can define a prefix to be put before each row in case an external app requires that Marking a shopping list as finished will hide it from the shopping list page","title":"Shopping"},{"location":"features/shopping/#create-shopping-lists","text":"You have three options to create a shopping list Open a recipe of your choice. From the context menu choose Add to Shoppinglist and create a new list with the recipe already added. After adding recipes to the meal plan you can click the little shopping cart icon to add the recipes to the shopping list. They will be shown below the plan, from there you can open a new shopping list with them. The last option is to open the shopping list page and click the little plus icon to create a new list.","title":"Create Shopping Lists"},{"location":"features/shopping/#supermarket-ordering","text":"WIP This feature is relatively new and I did not have the time to completely polished it yet, that said it already works quite well. You can create Supermarket Categories and Supermarkets in the admin interface. After setting this up you can choose a supermarket for each shopping list. This will automatically show the categories configured for this supermarket in the order specified. All Foods that are not yet categorized can be dragged into their category, this will save the categories for the future.","title":"Supermarket Ordering"},{"location":"features/shopping/#sharing-autosync","text":"If you want to collaborate on the creation and usage of the shopping list you can add a user to the list of shared users. Each user now has access to the list and can edit it. When checking items in viewing mode the change is synced to all other clients that currently have the same list open. You can set the syncing interval in your user settings.","title":"Sharing &amp; Autosync"},{"location":"features/shopping/#other-features","text":"There are a few more features worth pointing out You can export recipes for use in other applications (Google Keep, etc.) by using the export button In the export popup you can define a prefix to be put before each row in case an external app requires that Marking a shopping list as finished will hide it from the shopping list page","title":"Other Features"},{"location":"features/telegram_bot/","text":"The telegram bot is meant to simplify certain interactions with Tandoor. It is currently very basic but might be expanded in the future. Experimental This feature is considered experimental. You can use it and it should not break anything but you might be required to update your configuration in the future. The setup is also definitely not user-friendly, this will likely improve if the feature is well-received/expanded. Public IP/Domain To use the Telegram Bot you will need an installation that is accessible from the outside, otherwise telegram can't send messages. This could be circumvented using the polling API but this is currently not implemented. Shopping Bot The shopping bot will add any message you send it to your latest open shopping list. To get a shopping bot follow these steps Create a new Telegram Bot using the BotFather If you want to use the bot with multiple persons add the bot to a group and grant it admin privileges Open the Admin Page (click your username, then admin) and select Telegram Bots Create a new Bot token: the token obtained in step one space: your space (usually Default) user: to the user the bot is meant for (determines the shopping list used) chat id: if you know where messages will be sent from enter the chat ID, otherwise it is set to the first chat the bot received a message from Visit your installation at recipes.mydomin.tld/telegram/setup/<botid> with botid being the ID of the bot you just created You should see the following message: { \"hook_url\": \"https://recipes.mydomin.tld/telegram/hook/c0c08de9-5e1e-4480-8312-3e256af61340/\", \"create_response\": { \"ok\": true, \"result\": true, \"description\": \"Webhook was set\" }, \"info_response\": { \"ok\": true, \"result\": { \"url\": \"recipes.mydomin.tld/telegram/hook/<webhook_token>\", \"has_custom_certificate\": false, \"pending_update_count\": 0, \"max_connections\": 40, \"ip_address\": \"46.4.105.116\" } } } You should now be able to send messages to the bot and have the entries appear in your latest shopping list. Resetting To reset a bot open recipes.mydomin.tld/telegram/remove/<botid>","title":"Telegram bot"},{"location":"features/telegram_bot/#shopping-bot","text":"The shopping bot will add any message you send it to your latest open shopping list. To get a shopping bot follow these steps Create a new Telegram Bot using the BotFather If you want to use the bot with multiple persons add the bot to a group and grant it admin privileges Open the Admin Page (click your username, then admin) and select Telegram Bots Create a new Bot token: the token obtained in step one space: your space (usually Default) user: to the user the bot is meant for (determines the shopping list used) chat id: if you know where messages will be sent from enter the chat ID, otherwise it is set to the first chat the bot received a message from Visit your installation at recipes.mydomin.tld/telegram/setup/<botid> with botid being the ID of the bot you just created You should see the following message: { \"hook_url\": \"https://recipes.mydomin.tld/telegram/hook/c0c08de9-5e1e-4480-8312-3e256af61340/\", \"create_response\": { \"ok\": true, \"result\": true, \"description\": \"Webhook was set\" }, \"info_response\": { \"ok\": true, \"result\": { \"url\": \"recipes.mydomin.tld/telegram/hook/<webhook_token>\", \"has_custom_certificate\": false, \"pending_update_count\": 0, \"max_connections\": 40, \"ip_address\": \"46.4.105.116\" } } } You should now be able to send messages to the bot and have the entries appear in your latest shopping list.","title":"Shopping Bot"},{"location":"features/telegram_bot/#resetting","text":"To reset a bot open recipes.mydomin.tld/telegram/remove/<botid>","title":"Resetting"},{"location":"features/templating/","text":"Danger The version containing Templating is not yet released! This documentation is only to illustrate the pending changes facilitate the discussion. With the Version 0.14.0 support for using a custom Jinja2 Template in recipe step instructions has been added. This allows you to write ingredients with their corresponding amount directly inside the text while still profiting from recipe scaling. Info Templating is a very new feature and still WIP. Feel free to open an issue to provide feedback and ideas. Please also refer to Issue #218 where this feature has been discussed. Using Templating Currently the only available variable in the Templating context is ingredients . ingredients is an array that contains all ingredients of the current recipe step. You can access an ingredient by using {{ ingredients[<index in list>] }} where the index refers to the position in the list of ingredients starting with zero. You can also use the interaction menu of the ingredient to copy its reference. Warning Please note that changing the order of the ingredients will break the reference (or at least make it useless). See the technical reasoning for more information on why it is this way. You can also access only the amount, unit, note or food inside your instruction text using {{ ingredients[0].amount }} {{ ingredients[0].unit }} {{ ingredients[0].food }} {{ ingredients[0].note }} Technical Reasoning There are several options how the ingredients in the list can be related to the Template Context in the Text. The template could access them by ID, the food name or the position in the list. All options have their benefits and disadvantages. ID : ugly to write and read when not rendered and also more complex from a technical standpoint Name : very nice to read and easy but does not work when a food occurs twice in a step. Could have workaround but would then be inconsistent. Position : easy to write and understand but breaks when ordering is changed and not really nice to read when instructions are not rendered. I decided to go for the position based system. If you know of any better way feel free to open an issue or PR.","title":"Templating"},{"location":"features/templating/#using-templating","text":"Currently the only available variable in the Templating context is ingredients . ingredients is an array that contains all ingredients of the current recipe step. You can access an ingredient by using {{ ingredients[<index in list>] }} where the index refers to the position in the list of ingredients starting with zero. You can also use the interaction menu of the ingredient to copy its reference. Warning Please note that changing the order of the ingredients will break the reference (or at least make it useless). See the technical reasoning for more information on why it is this way. You can also access only the amount, unit, note or food inside your instruction text using {{ ingredients[0].amount }} {{ ingredients[0].unit }} {{ ingredients[0].food }} {{ ingredients[0].note }}","title":"Using Templating"},{"location":"features/templating/#technical-reasoning","text":"There are several options how the ingredients in the list can be related to the Template Context in the Text. The template could access them by ID, the food name or the position in the list. All options have their benefits and disadvantages. ID : ugly to write and read when not rendered and also more complex from a technical standpoint Name : very nice to read and easy but does not work when a food occurs twice in a step. Could have workaround but would then be inconsistent. Position : easy to write and understand but breaks when ordering is changed and not really nice to read when instructions are not rendered. I decided to go for the position based system. If you know of any better way feel free to open an issue or PR.","title":"Technical Reasoning"},{"location":"install/docker/","text":"Recommended Installation Setting up this application using Docker is recommended. This does not mean that other options are bad, just that support is much easier for this setup. It is possible to install this application using many different Docker configurations. Please read the instructions on each example carefully and decide if this is the way for you. Docker The docker image ( vabene1111/recipes ) simply exposes the application on the container's port 8080 . It can be run and accessed on port 80 using: docker run -d \\ -v \" $( pwd ) \" /staticfiles:/opt/recipes/staticfiles \\ -v \" $( pwd ) \" /mediafiles:/opt/recipes/mediafiles \\ -p 80 :8080 \\ -e SECRET_KEY = YOUR_SECRET_KEY \\ -e DB_ENGINE = django.db.backends.postgresql \\ -e POSTGRES_HOST = db_recipes \\ -e POSTGRES_PORT = 5432 \\ -e POSTGRES_USER = djangodb \\ -e POSTGRES_PASSWORD = YOUR_POSTGRES_SECRET_KEY \\ -e POSTGRES_DB = djangodb \\ --name recipes_1 \\ vabene1111/recipes Please make sure, if you run your image this way, to consult the .env.template file in the GitHub repository to verify if additional environment variables are required for your setup. Also, don't forget to replace the placeholders for SECRET_KEY and POSTGRES_PASSWORD ! Versions There are different versions (tags) released on Docker Hub . latest Default image. The one you should use if you don't know that you need anything else. beta Partially stable version that gets updated every now and then. Expect to have some problems. develop If you want the most bleeding edge version with potentially many breaking changes feel free to use this version (not recommended!). X.Y.Z each released version has its own image. If you need to revert to an old version or want to make sure you stay on one specific use these tags. No Downgrading There is currently no way to migrate back to an older version as there is no mechanism to downgrade the database. You could probably do it but I cannot help you with that. Choose wisely if you want to use the unstable images. That said beta should usually be working if you like frequent updates and new stuff. Docker Compose The main, and also recommended, installation option for this application is Docker Compose. Choose your docker-compose.yml from the examples below. Download the .env configuration file with wget wget https://raw.githubusercontent.com/vabene1111/recipes/develop/.env.template -O .env Edit it accordingly (you NEED to set SECRET_KEY and POSTGRES_PASSWORD ). Start your container using docker-compose up -d . Plain This configuration exposes the application through a containerized nginx web server on port 80 of your machine. Be aware that having some other web server or container running on your host machine on port 80 will block this from working. wget https://raw.githubusercontent.com/vabene1111/recipes/develop/docs/install/docker/plain/docker-compose.yml version : \"3\" services : db_recipes : restart : always image : postgres:11-alpine volumes : - ./postgresql:/var/lib/postgresql/data env_file : - ./.env web_recipes : restart : always image : vabene1111/recipes env_file : - ./.env ports : - 80:8080 volumes : - staticfiles:/opt/recipes/staticfiles - nginx_config:/opt/recipes/nginx/conf.d - ./mediafiles:/opt/recipes/mediafiles depends_on : - db_recipes nginx_recipes : image : nginx:mainline-alpine restart : always ports : env_file : - ./.env depends_on : - web_recipes volumes : - nginx_config:/etc/nginx/conf.d:ro - staticfiles:/static:ro - ./mediafiles:/media:ro volumes : nginx_config : staticfiles : Note Don't forget to download and configure your .env file! Reverse Proxy Most deployments will likely use a reverse proxy. If your reverse proxy is not listed below, please refer to chapter Others . Traefik If you use Traefik, this configuration is the one for you. Info Traefik can be a little confusing to setup. Please refer to their excellent documentation . If that does not help, this little example might be for you. wget https://raw.githubusercontent.com/vabene1111/recipes/develop/docs/install/docker/traefik-nginx/docker-compose.yml version : \"3\" services : db_recipes : restart : always image : postgres:11-alpine volumes : - ./postgresql:/var/lib/postgresql/data env_file : - ./.env networks : - default web_recipes : restart : always image : vabene1111/recipes env_file : - ./.env volumes : - staticfiles:/opt/recipes/staticfiles - nginx_config:/opt/recipes/nginx/conf.d - ./mediafiles:/opt/recipes/mediafiles depends_on : - db_recipes networks : - default nginx_recipes : image : nginx:mainline-alpine restart : always env_file : - ./.env volumes : - nginx_config:/etc/nginx/conf.d:ro - staticfiles:/static:ro - ./mediafiles:/media:ro labels : # traefik example labels - \"traefik.enable=true\" - \"traefik.http.routers.recipes.rule=Host(`recipes.mydomain.com`, `recipes.myotherdomain.com`)\" - \"traefik.http.routers.recipes.entrypoints=web_secure\" # your https endpoint - \"traefik.http.routers.recipes.tls.certresolver=le_resolver\" # your cert resolver depends_on : - web_recipes networks : - default - traefik networks : default : traefik : # This is your external traefik network external : true volumes : nginx_config : staticfiles : Note Don't forget to download and configure your .env file! jwilder's Nginx-proxy This is a docker compose example using jwilder's nginx reverse proxy in combination with jrcs's letsencrypt companion . Please refer to the appropriate documentation on how to setup the reverse proxy and networks. Adjust client_max_body_size By using jwilder's Nginx-proxy, uploads will be restricted to 1 MB file size. This can be resolved by adjusting the client_max_body_size variable in the jwilder nginx configuration. Remember to add the appropriate environment variables to the .env file: VIRTUAL_HOST= LETSENCRYPT_HOST= LETSENCRYPT_EMAIL= wget https://raw.githubusercontent.com/vabene1111/recipes/develop/docs/install/docker/nginx-proxy/docker-compose.yml version : \"3\" services : db_recipes : restart : always image : postgres:11-alpine volumes : - ./postgresql:/var/lib/postgresql/data env_file : - ./.env networks : - default web_recipes : restart : always image : vabene1111/recipes env_file : - ./.env volumes : - staticfiles:/opt/recipes/staticfiles - nginx_config:/opt/recipes/nginx/conf.d - ./mediafiles:/opt/recipes/mediafiles depends_on : - db_recipes networks : - default nginx_recipes : image : nginx:mainline-alpine restart : always env_file : - ./.env depends_on : - web_recipes volumes : - nginx_config:/etc/nginx/conf.d:ro - staticfiles:/static:ro - ./mediafiles:/media:ro networks : - default - nginx-proxy networks : default : nginx-proxy : external : name : nginx-proxy volumes : nginx_config : staticfiles : Note Don't forget to download and configure your .env file! Nginx Swag by LinuxServer This container is an all in one solution created by LinuxServer.io. It contains templates for popular apps, including Tandoor Recipes, so you don't have to manually configure nginx and discard the template provided in Tandoor repo. Tandoor config is called recipes.subdomain.conf.sample which you can adapt for your instance. If you're running Swag on the default port, you'll just need to change the container name to yours. If your running Swag on a custom port, some headers must be changed: Create a copy of proxy.conf Replace proxy_set_header X-Forwarded-Host $host; and proxy_set_header Host $host; to proxy_set_header X-Forwarded-Host $http_host; and proxy_set_header Host $http_host; Update recipes.subdomain.conf to use the new file Restart the linuxserver/swag container and Recipes will work correctly More information here . In both cases, also make sure to mount /media/ in your swag container to point to your Tandoor Recipes Media directory. Please refer to the appropriate documentation for the container setup. For step-by-step instructions to set this up from scratch, see this example . Pure Nginx If you have Nginx installed locally on your host system without using any third party integration like Swag or similar, this is for you. You can use the Docker-Compose file from Plain . Adjust Docker-Compose file Replace 80:80 with PORT:80 with PORT being your desired outward-facing port. In the nginx config example below, 8080 is used. An example configuration with LetsEncrypt to get you started can be seen below. Please note, that since every setup is different, you might need to adjust some things. Placeholders Don't forget to replace the domain and port. server { if ( $host = recipes.mydomain.tld) { # replace domain return 301 https:// $host$request_uri ; } server_name recipes.mydomain.tld ; # replace domain listen 80 ; return 404 ; } server { server_name recipes.mydomain.tld ; # replace domain listen 443 ssl ; ssl_certificate /etc/letsencrypt/live/recipes.mydomain.tld/fullchain.pem ; # replace domain ssl_certificate_key /etc/letsencrypt/live/recipes.mydomain.tld/privkey.pem ; # replace domain include /etc/letsencrypt/options-ssl-nginx.conf ; ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem ; location / { proxy_set_header Host $http_host ; # try $host instead if this doesn't work proxy_set_header X-Forwarded-Proto $scheme ; proxy_pass http://127.0.0.1:8080 ; # replace port proxy_redirect http://127.0.0.1:8080 https://recipes.domain.tld ; # replace port and domain } } Note Don't forget to download and configure your .env file! Apache You can use the Docker-Compose file from Plain . Adjust Docker-Compose file Replace 80:80 with PORT:80 with PORT being your desired outward-facing port. In the Apache config example below, 8080 is used. If you use e.g. LetsEncrypt for SSL encryption, you can use the example configuration from solaris7590 below. Placeholders Don't forget to replace the domain and port. <IfModule mod_ssl.c > <VirtualHost *:80 > ServerAdmin webmaster@mydomain.de # replace domain ServerName mydomain.de # replace domain Redirect permanent / https://mydomain.de/ # replace domain </VirtualHost> <VirtualHost *:443 > ServerAdmin webmaster@mydomain.de # replace domain ServerName mydomain.de # replace domain SSLEngine on RequestHeader set X-Forwarded-Proto \"https\" Header always set Access-Control-Allow-Origin \"*\" ProxyPreserveHost On ProxyRequests Off ProxyPass / http://localhost:8080/ # replace port ProxyPassReverse / http://localhost:8080/ # replace port SSLCertificateFile /etc/letsencrypt/live/mydomain.de/fullchain.pem # replace domain/path SSLCertificateKeyFile /etc/letsencrypt/live/mydomain.de/privkey.pem # replace domain/path Include /etc/letsencrypt/options-ssl-apache.conf ErrorLog ${APACHE_LOG_DIR}/recipes_error.log CustomLog ${APACHE_LOG_DIR}/recipes_access.log combined </VirtualHost> </IfModule> If you're having issues with the example configuration above, you can try beedaddy 's example config. Note Don't forget to download and configure your .env file! Others If you use none of the above mentioned reverse proxies or want to use an existing one on your host machine (like a local nginx or Caddy), simply use the Plain setup above and change the outbound port to one of your liking. An example port config (inside the respective docker-compose.yml) would be: 8123:80 instead of the 80:80 or if you want to be sure, that Tandoor is just accessible via your proxy and don't wanna bother with your firewall, then 127.0.0.1:8123:80 is a viable option too. Note Don't forget to download and configure your .env file! Additional Information Nginx vs Gunicorn All examples use an additional nginx container to serve mediafiles and act as the forward facing webserver. This is technically not required but very much recommended . I do not 100% understand the deep technical details but the developers of gunicorn , the WSGi server that handles the Python execution, explicitly state that it is not recommended to deploy without nginx. You will also likely not see any decrease in performance or a lot of space used as nginx is a very light container. Info Even if you run behind a reverse proxy as described above, using an additional nginx container is the recommended option. If you run a small private deployment and don't care about performance, security and whatever else feel free to run without a nginx container. Warning When running without nginx make sure to enable GUNICORN_MEDIA in the .env . Without it, media files will be uploaded but not shown on the page. For additional information please refer to the 0.9.0 Release and Issue 201 where these topics have been discussed. See also refer to the official gunicorn docs . Nginx Config In order to give the user (you) the greatest amount of freedom when choosing how to deploy this application the webserver is not directly bundled with the Docker image. This has the downside that it is difficult to supply the configuration to the webserver (e.g. nginx). Up until version 0.13.0 , this had to be done manually by downloading the nginx config file and placing it in a directory that was then mounted into the nginx container. From version 0.13.0 , the config file is supplied using the application image ( vabene1111/recipes ). It is then mounted to the host system and from there into the nginx container. This is not really a clean solution, but I could not find any better alternative that provided the same amount of usability. If you know of any better way, feel free to open an issue. Volumes vs Bind Mounts Since I personally prefer to have my data where my docker-compose.yml resides, bind mounts are used in the example configuration files for all user generated data (e.g. Postgresql and media files). Warning Please note that there is a difference in functionality between the two and you cannot always simply interchange them. You can move everything to volumes if you prefer it this way, but you cannot convert the nginx config file to a bind mount. If you do so you will have to manually create the nginx config file and restart the container once after creating it. Required Headers Please be sure to supply all required headers in your nginx/Apache/Caddy/... configuration! nginx: location / { proxy_set_header Host $http_host ; # try $host instead if this doesn't work proxy_set_header X-Forwarded-Proto $scheme ; proxy_pass http://127.0.0.1:8080 ; # replace port proxy_redirect http://127.0.0.1:8080 https://recipes.domain.tld ; # replace port and domain } Apache: RequestHeader set X-Forwarded-Proto \"https\" Header always set Access-Control-Allow-Origin \"*\" ProxyPreserveHost On ProxyRequests Off ProxyPass / http://localhost:8080/ # replace port ProxyPassReverse / http://localhost:8080/ # replace port Setup issues on Raspberry Pi Info Always wait at least 2-3 minutes after the very first start, since migrations will take some time! Warning If you want to use Tandoor on a Raspberry Pi running a 32-bit operating system you will need to use the following docker image tags: latest-raspi , beta-raspi and the versioned <x.y.z>-raspi We strongly recommend using the new 64-bit Raspian image as the 32-bit version is not tested. If you're having issues with installing Tandoor on your Raspberry Pi or similar device, follow these instructions: Stop all Tandoor containers ( docker-compose down ) Delete local database folder (usually 'postgresql' in the same folder as your 'docker-compose.yml' file) Start Tandoor containers again ( docker-compose up -d ) Wait for at least 2-3 minutes and then check if everything is working now (migrations can take quite some time!) If not, check logs of the web_recipes container with docker logs <container_name> and make sure that all migrations are indeed already done Sub Path nginx config If hosting under a sub-path you might want to change the default nginx config (which gets mounted through the named volume from the application container into the nginx container) with the following config. location /my_app { # change to subfolder name include /config/nginx/proxy.conf ; proxy_pass https://mywebapp.com/ ; # change to your host name:port proxy_set_header Host $host ; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for ; proxy_set_header X-Script-Name /my_app ; # change to subfolder name proxy_cookie_path / /my_app ; # change to subfolder name } location /media/ { include /config/nginx/proxy.conf ; alias /mediafiles/ ; client_max_body_size 16M ; } location /static/ { include /config/nginx/proxy.conf ; alias /staticfiles/ ; client_max_body_size 16M ; }","title":"Docker"},{"location":"install/docker/#docker","text":"The docker image ( vabene1111/recipes ) simply exposes the application on the container's port 8080 . It can be run and accessed on port 80 using: docker run -d \\ -v \" $( pwd ) \" /staticfiles:/opt/recipes/staticfiles \\ -v \" $( pwd ) \" /mediafiles:/opt/recipes/mediafiles \\ -p 80 :8080 \\ -e SECRET_KEY = YOUR_SECRET_KEY \\ -e DB_ENGINE = django.db.backends.postgresql \\ -e POSTGRES_HOST = db_recipes \\ -e POSTGRES_PORT = 5432 \\ -e POSTGRES_USER = djangodb \\ -e POSTGRES_PASSWORD = YOUR_POSTGRES_SECRET_KEY \\ -e POSTGRES_DB = djangodb \\ --name recipes_1 \\ vabene1111/recipes Please make sure, if you run your image this way, to consult the .env.template file in the GitHub repository to verify if additional environment variables are required for your setup. Also, don't forget to replace the placeholders for SECRET_KEY and POSTGRES_PASSWORD !","title":"Docker"},{"location":"install/docker/#versions","text":"There are different versions (tags) released on Docker Hub . latest Default image. The one you should use if you don't know that you need anything else. beta Partially stable version that gets updated every now and then. Expect to have some problems. develop If you want the most bleeding edge version with potentially many breaking changes feel free to use this version (not recommended!). X.Y.Z each released version has its own image. If you need to revert to an old version or want to make sure you stay on one specific use these tags. No Downgrading There is currently no way to migrate back to an older version as there is no mechanism to downgrade the database. You could probably do it but I cannot help you with that. Choose wisely if you want to use the unstable images. That said beta should usually be working if you like frequent updates and new stuff.","title":"Versions"},{"location":"install/docker/#docker-compose","text":"The main, and also recommended, installation option for this application is Docker Compose. Choose your docker-compose.yml from the examples below. Download the .env configuration file with wget wget https://raw.githubusercontent.com/vabene1111/recipes/develop/.env.template -O .env Edit it accordingly (you NEED to set SECRET_KEY and POSTGRES_PASSWORD ). Start your container using docker-compose up -d .","title":"Docker Compose"},{"location":"install/docker/#plain","text":"This configuration exposes the application through a containerized nginx web server on port 80 of your machine. Be aware that having some other web server or container running on your host machine on port 80 will block this from working. wget https://raw.githubusercontent.com/vabene1111/recipes/develop/docs/install/docker/plain/docker-compose.yml version : \"3\" services : db_recipes : restart : always image : postgres:11-alpine volumes : - ./postgresql:/var/lib/postgresql/data env_file : - ./.env web_recipes : restart : always image : vabene1111/recipes env_file : - ./.env ports : - 80:8080 volumes : - staticfiles:/opt/recipes/staticfiles - nginx_config:/opt/recipes/nginx/conf.d - ./mediafiles:/opt/recipes/mediafiles depends_on : - db_recipes nginx_recipes : image : nginx:mainline-alpine restart : always ports : env_file : - ./.env depends_on : - web_recipes volumes : - nginx_config:/etc/nginx/conf.d:ro - staticfiles:/static:ro - ./mediafiles:/media:ro volumes : nginx_config : staticfiles : Note Don't forget to download and configure your .env file!","title":"Plain"},{"location":"install/docker/#reverse-proxy","text":"Most deployments will likely use a reverse proxy. If your reverse proxy is not listed below, please refer to chapter Others .","title":"Reverse Proxy"},{"location":"install/docker/#traefik","text":"If you use Traefik, this configuration is the one for you. Info Traefik can be a little confusing to setup. Please refer to their excellent documentation . If that does not help, this little example might be for you. wget https://raw.githubusercontent.com/vabene1111/recipes/develop/docs/install/docker/traefik-nginx/docker-compose.yml version : \"3\" services : db_recipes : restart : always image : postgres:11-alpine volumes : - ./postgresql:/var/lib/postgresql/data env_file : - ./.env networks : - default web_recipes : restart : always image : vabene1111/recipes env_file : - ./.env volumes : - staticfiles:/opt/recipes/staticfiles - nginx_config:/opt/recipes/nginx/conf.d - ./mediafiles:/opt/recipes/mediafiles depends_on : - db_recipes networks : - default nginx_recipes : image : nginx:mainline-alpine restart : always env_file : - ./.env volumes : - nginx_config:/etc/nginx/conf.d:ro - staticfiles:/static:ro - ./mediafiles:/media:ro labels : # traefik example labels - \"traefik.enable=true\" - \"traefik.http.routers.recipes.rule=Host(`recipes.mydomain.com`, `recipes.myotherdomain.com`)\" - \"traefik.http.routers.recipes.entrypoints=web_secure\" # your https endpoint - \"traefik.http.routers.recipes.tls.certresolver=le_resolver\" # your cert resolver depends_on : - web_recipes networks : - default - traefik networks : default : traefik : # This is your external traefik network external : true volumes : nginx_config : staticfiles : Note Don't forget to download and configure your .env file!","title":"Traefik"},{"location":"install/docker/#jwilders-nginx-proxy","text":"This is a docker compose example using jwilder's nginx reverse proxy in combination with jrcs's letsencrypt companion . Please refer to the appropriate documentation on how to setup the reverse proxy and networks. Adjust client_max_body_size By using jwilder's Nginx-proxy, uploads will be restricted to 1 MB file size. This can be resolved by adjusting the client_max_body_size variable in the jwilder nginx configuration. Remember to add the appropriate environment variables to the .env file: VIRTUAL_HOST= LETSENCRYPT_HOST= LETSENCRYPT_EMAIL= wget https://raw.githubusercontent.com/vabene1111/recipes/develop/docs/install/docker/nginx-proxy/docker-compose.yml version : \"3\" services : db_recipes : restart : always image : postgres:11-alpine volumes : - ./postgresql:/var/lib/postgresql/data env_file : - ./.env networks : - default web_recipes : restart : always image : vabene1111/recipes env_file : - ./.env volumes : - staticfiles:/opt/recipes/staticfiles - nginx_config:/opt/recipes/nginx/conf.d - ./mediafiles:/opt/recipes/mediafiles depends_on : - db_recipes networks : - default nginx_recipes : image : nginx:mainline-alpine restart : always env_file : - ./.env depends_on : - web_recipes volumes : - nginx_config:/etc/nginx/conf.d:ro - staticfiles:/static:ro - ./mediafiles:/media:ro networks : - default - nginx-proxy networks : default : nginx-proxy : external : name : nginx-proxy volumes : nginx_config : staticfiles : Note Don't forget to download and configure your .env file!","title":"jwilder's Nginx-proxy"},{"location":"install/docker/#nginx-swag-by-linuxserver","text":"This container is an all in one solution created by LinuxServer.io. It contains templates for popular apps, including Tandoor Recipes, so you don't have to manually configure nginx and discard the template provided in Tandoor repo. Tandoor config is called recipes.subdomain.conf.sample which you can adapt for your instance. If you're running Swag on the default port, you'll just need to change the container name to yours. If your running Swag on a custom port, some headers must be changed: Create a copy of proxy.conf Replace proxy_set_header X-Forwarded-Host $host; and proxy_set_header Host $host; to proxy_set_header X-Forwarded-Host $http_host; and proxy_set_header Host $http_host; Update recipes.subdomain.conf to use the new file Restart the linuxserver/swag container and Recipes will work correctly More information here . In both cases, also make sure to mount /media/ in your swag container to point to your Tandoor Recipes Media directory. Please refer to the appropriate documentation for the container setup. For step-by-step instructions to set this up from scratch, see this example .","title":"Nginx Swag by LinuxServer"},{"location":"install/docker/#pure-nginx","text":"If you have Nginx installed locally on your host system without using any third party integration like Swag or similar, this is for you. You can use the Docker-Compose file from Plain . Adjust Docker-Compose file Replace 80:80 with PORT:80 with PORT being your desired outward-facing port. In the nginx config example below, 8080 is used. An example configuration with LetsEncrypt to get you started can be seen below. Please note, that since every setup is different, you might need to adjust some things. Placeholders Don't forget to replace the domain and port. server { if ( $host = recipes.mydomain.tld) { # replace domain return 301 https:// $host$request_uri ; } server_name recipes.mydomain.tld ; # replace domain listen 80 ; return 404 ; } server { server_name recipes.mydomain.tld ; # replace domain listen 443 ssl ; ssl_certificate /etc/letsencrypt/live/recipes.mydomain.tld/fullchain.pem ; # replace domain ssl_certificate_key /etc/letsencrypt/live/recipes.mydomain.tld/privkey.pem ; # replace domain include /etc/letsencrypt/options-ssl-nginx.conf ; ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem ; location / { proxy_set_header Host $http_host ; # try $host instead if this doesn't work proxy_set_header X-Forwarded-Proto $scheme ; proxy_pass http://127.0.0.1:8080 ; # replace port proxy_redirect http://127.0.0.1:8080 https://recipes.domain.tld ; # replace port and domain } } Note Don't forget to download and configure your .env file!","title":"Pure Nginx"},{"location":"install/docker/#apache","text":"You can use the Docker-Compose file from Plain . Adjust Docker-Compose file Replace 80:80 with PORT:80 with PORT being your desired outward-facing port. In the Apache config example below, 8080 is used. If you use e.g. LetsEncrypt for SSL encryption, you can use the example configuration from solaris7590 below. Placeholders Don't forget to replace the domain and port. <IfModule mod_ssl.c > <VirtualHost *:80 > ServerAdmin webmaster@mydomain.de # replace domain ServerName mydomain.de # replace domain Redirect permanent / https://mydomain.de/ # replace domain </VirtualHost> <VirtualHost *:443 > ServerAdmin webmaster@mydomain.de # replace domain ServerName mydomain.de # replace domain SSLEngine on RequestHeader set X-Forwarded-Proto \"https\" Header always set Access-Control-Allow-Origin \"*\" ProxyPreserveHost On ProxyRequests Off ProxyPass / http://localhost:8080/ # replace port ProxyPassReverse / http://localhost:8080/ # replace port SSLCertificateFile /etc/letsencrypt/live/mydomain.de/fullchain.pem # replace domain/path SSLCertificateKeyFile /etc/letsencrypt/live/mydomain.de/privkey.pem # replace domain/path Include /etc/letsencrypt/options-ssl-apache.conf ErrorLog ${APACHE_LOG_DIR}/recipes_error.log CustomLog ${APACHE_LOG_DIR}/recipes_access.log combined </VirtualHost> </IfModule> If you're having issues with the example configuration above, you can try beedaddy 's example config. Note Don't forget to download and configure your .env file!","title":"Apache"},{"location":"install/docker/#others","text":"If you use none of the above mentioned reverse proxies or want to use an existing one on your host machine (like a local nginx or Caddy), simply use the Plain setup above and change the outbound port to one of your liking. An example port config (inside the respective docker-compose.yml) would be: 8123:80 instead of the 80:80 or if you want to be sure, that Tandoor is just accessible via your proxy and don't wanna bother with your firewall, then 127.0.0.1:8123:80 is a viable option too. Note Don't forget to download and configure your .env file!","title":"Others"},{"location":"install/docker/#additional-information","text":"","title":"Additional Information"},{"location":"install/docker/#nginx-vs-gunicorn","text":"All examples use an additional nginx container to serve mediafiles and act as the forward facing webserver. This is technically not required but very much recommended . I do not 100% understand the deep technical details but the developers of gunicorn , the WSGi server that handles the Python execution, explicitly state that it is not recommended to deploy without nginx. You will also likely not see any decrease in performance or a lot of space used as nginx is a very light container. Info Even if you run behind a reverse proxy as described above, using an additional nginx container is the recommended option. If you run a small private deployment and don't care about performance, security and whatever else feel free to run without a nginx container. Warning When running without nginx make sure to enable GUNICORN_MEDIA in the .env . Without it, media files will be uploaded but not shown on the page. For additional information please refer to the 0.9.0 Release and Issue 201 where these topics have been discussed. See also refer to the official gunicorn docs .","title":"Nginx vs Gunicorn"},{"location":"install/docker/#nginx-config","text":"In order to give the user (you) the greatest amount of freedom when choosing how to deploy this application the webserver is not directly bundled with the Docker image. This has the downside that it is difficult to supply the configuration to the webserver (e.g. nginx). Up until version 0.13.0 , this had to be done manually by downloading the nginx config file and placing it in a directory that was then mounted into the nginx container. From version 0.13.0 , the config file is supplied using the application image ( vabene1111/recipes ). It is then mounted to the host system and from there into the nginx container. This is not really a clean solution, but I could not find any better alternative that provided the same amount of usability. If you know of any better way, feel free to open an issue.","title":"Nginx Config"},{"location":"install/docker/#volumes-vs-bind-mounts","text":"Since I personally prefer to have my data where my docker-compose.yml resides, bind mounts are used in the example configuration files for all user generated data (e.g. Postgresql and media files). Warning Please note that there is a difference in functionality between the two and you cannot always simply interchange them. You can move everything to volumes if you prefer it this way, but you cannot convert the nginx config file to a bind mount. If you do so you will have to manually create the nginx config file and restart the container once after creating it.","title":"Volumes vs Bind Mounts"},{"location":"install/docker/#required-headers","text":"Please be sure to supply all required headers in your nginx/Apache/Caddy/... configuration! nginx: location / { proxy_set_header Host $http_host ; # try $host instead if this doesn't work proxy_set_header X-Forwarded-Proto $scheme ; proxy_pass http://127.0.0.1:8080 ; # replace port proxy_redirect http://127.0.0.1:8080 https://recipes.domain.tld ; # replace port and domain } Apache: RequestHeader set X-Forwarded-Proto \"https\" Header always set Access-Control-Allow-Origin \"*\" ProxyPreserveHost On ProxyRequests Off ProxyPass / http://localhost:8080/ # replace port ProxyPassReverse / http://localhost:8080/ # replace port","title":"Required Headers"},{"location":"install/docker/#setup-issues-on-raspberry-pi","text":"Info Always wait at least 2-3 minutes after the very first start, since migrations will take some time! Warning If you want to use Tandoor on a Raspberry Pi running a 32-bit operating system you will need to use the following docker image tags: latest-raspi , beta-raspi and the versioned <x.y.z>-raspi We strongly recommend using the new 64-bit Raspian image as the 32-bit version is not tested. If you're having issues with installing Tandoor on your Raspberry Pi or similar device, follow these instructions: Stop all Tandoor containers ( docker-compose down ) Delete local database folder (usually 'postgresql' in the same folder as your 'docker-compose.yml' file) Start Tandoor containers again ( docker-compose up -d ) Wait for at least 2-3 minutes and then check if everything is working now (migrations can take quite some time!) If not, check logs of the web_recipes container with docker logs <container_name> and make sure that all migrations are indeed already done","title":"Setup issues on Raspberry Pi"},{"location":"install/docker/#sub-path-nginx-config","text":"If hosting under a sub-path you might want to change the default nginx config (which gets mounted through the named volume from the application container into the nginx container) with the following config. location /my_app { # change to subfolder name include /config/nginx/proxy.conf ; proxy_pass https://mywebapp.com/ ; # change to your host name:port proxy_set_header Host $host ; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for ; proxy_set_header X-Script-Name /my_app ; # change to subfolder name proxy_cookie_path / /my_app ; # change to subfolder name } location /media/ { include /config/nginx/proxy.conf ; alias /mediafiles/ ; client_max_body_size 16M ; } location /static/ { include /config/nginx/proxy.conf ; alias /staticfiles/ ; client_max_body_size 16M ; }","title":"Sub Path nginx config"},{"location":"install/homeassistant/","text":"Community Contributed This guide was contributed by the community and is neither officially supported, nor updated or tested. Many thanks to alexbelgium for making implementing everything required to have Tandoor run in HA. Introduction Home Assistant (HA) is a free and open-source software for home automation designed to be a central control system for smart home devices with a focus on local control and privacy. It can be accessed through a web-based user interface by using companion apps for Android and iOS, or by voice commands via a supported virtual assistant such as Google Assistant or Amazon Alexa. It can be installed as a standalone Operating System on a dedicated system, making it easy to deploy and maintain through Over The Air updates. It can also be installed as Docker container. In addition to its large depth of native functions, modular addons can be added to expand its functions. An addon for Tandoor Recipes was created, allowing to store the server on the Home Assistant devices and access the user interface either through direct web access or securely through the native Home Assistant app. Installation Once you have a running Home Assistant system, the next step is to add the alexbelgium 's custom repository to your system. This is performed by clicking on the button below, and simply filling your HA url. Install the addon Set the add-on options to your preferences (see below) Start the add-on Check the logs of the add-on to see if everything went well. Open the webUI (either through Ingress, or direct webUI with http://homeassistant.local:9928) and adapt the software options Configuration The following environment variable are configurable from the addon options. Please see the Docker documentation for more information on how they should be filled. Required : \"ALLOWED_HOSTS\" : \"your system url\" , # You need to input your homeassistant urls (comma separated, without space) to allow ingress to work \"DB_TYPE\" : \"list(sqlite|postgresql_external|mariadb_addon)\" # Type of database to use. Mariadb_addon allows to be automatically configured if the maria_db addon is already installed on your system. Sqlite is an internal database. For postgresql_external, you'll need to fill the below settings \"SECRET_KEY\" : \"str\" , # Your secret key \"PORT\" : 9928 # By default, the webui is available on http://homeassistant.local:9928. If you ever need to change the port, you should never do it within the app, but only through this option Optional : \"POSTGRES_HOST\" : \"str?\" , # Needed for postgresql_external \"POSTGRES_PORT\" : \"str?\" , # Needed for postgresql_external \"POSTGRES_USER\" : \"str?\" , # Needed for postgresql_external \"POSTGRES_PASSWORD\" : \"str?\" , # Needed for postgresql_external \"POSTGRES_DB\" : \"str?\" # Needed for postgresql_external Updates and backups The alexbelgium's repo incorporates a script that aligns every 3 days the addon to the containers released. Just wait a few hours for HA to refreshes its repo list and the uodate will be proposed automatically in your HA system. It is recommended to frequently backup. All data is stored outside of the addon, the main location /config/addons_config/tandoor_recipes , so be sure to backup this folder in addition to the addon itself when updating. If you have selected mariadb as database option, don't forget to also backup it. Support Issues related to the addon itself should be reported on the maintainer repo . Issues related to HA should be reported on the HA Community Forum . Issues related to Tandoor recipes should be reported on this github repo.","title":"Homeassistant"},{"location":"install/homeassistant/#introduction","text":"Home Assistant (HA) is a free and open-source software for home automation designed to be a central control system for smart home devices with a focus on local control and privacy. It can be accessed through a web-based user interface by using companion apps for Android and iOS, or by voice commands via a supported virtual assistant such as Google Assistant or Amazon Alexa. It can be installed as a standalone Operating System on a dedicated system, making it easy to deploy and maintain through Over The Air updates. It can also be installed as Docker container. In addition to its large depth of native functions, modular addons can be added to expand its functions. An addon for Tandoor Recipes was created, allowing to store the server on the Home Assistant devices and access the user interface either through direct web access or securely through the native Home Assistant app.","title":"Introduction"},{"location":"install/homeassistant/#installation","text":"Once you have a running Home Assistant system, the next step is to add the alexbelgium 's custom repository to your system. This is performed by clicking on the button below, and simply filling your HA url. Install the addon Set the add-on options to your preferences (see below) Start the add-on Check the logs of the add-on to see if everything went well. Open the webUI (either through Ingress, or direct webUI with http://homeassistant.local:9928) and adapt the software options","title":"Installation"},{"location":"install/homeassistant/#configuration","text":"The following environment variable are configurable from the addon options. Please see the Docker documentation for more information on how they should be filled. Required : \"ALLOWED_HOSTS\" : \"your system url\" , # You need to input your homeassistant urls (comma separated, without space) to allow ingress to work \"DB_TYPE\" : \"list(sqlite|postgresql_external|mariadb_addon)\" # Type of database to use. Mariadb_addon allows to be automatically configured if the maria_db addon is already installed on your system. Sqlite is an internal database. For postgresql_external, you'll need to fill the below settings \"SECRET_KEY\" : \"str\" , # Your secret key \"PORT\" : 9928 # By default, the webui is available on http://homeassistant.local:9928. If you ever need to change the port, you should never do it within the app, but only through this option Optional : \"POSTGRES_HOST\" : \"str?\" , # Needed for postgresql_external \"POSTGRES_PORT\" : \"str?\" , # Needed for postgresql_external \"POSTGRES_USER\" : \"str?\" , # Needed for postgresql_external \"POSTGRES_PASSWORD\" : \"str?\" , # Needed for postgresql_external \"POSTGRES_DB\" : \"str?\" # Needed for postgresql_external","title":"Configuration"},{"location":"install/homeassistant/#updates-and-backups","text":"The alexbelgium's repo incorporates a script that aligns every 3 days the addon to the containers released. Just wait a few hours for HA to refreshes its repo list and the uodate will be proposed automatically in your HA system. It is recommended to frequently backup. All data is stored outside of the addon, the main location /config/addons_config/tandoor_recipes , so be sure to backup this folder in addition to the addon itself when updating. If you have selected mariadb as database option, don't forget to also backup it.","title":"Updates and backups"},{"location":"install/homeassistant/#support","text":"Issues related to the addon itself should be reported on the maintainer repo . Issues related to HA should be reported on the HA Community Forum . Issues related to Tandoor recipes should be reported on this github repo.","title":"Support"},{"location":"install/kubernetes/","text":"Community Contributed This guide was contributed by the community and is neither officially supported, nor updated or tested. K8s Setup This is a setup which should be sufficient for production use. Be sure to replace the default secrets! Files 10-configmap.yaml The nginx config map. This is loaded as nginx.conf in the nginx sidecar to configure nginx to deliver static content. 15-secrets.yaml Contains secrets Replace them! This file is only here for a quick start. Be aware that changing secrets after installation will be messy and is not documented here. You should set new secrets before the installation. As you are reading this document before the installation ;-) Create your own postgresql passwords and the secret key for the django app. See also Managing Secrets using kubectl Replace db-password , postgres-user-password and secret-key with something - well - secret :-) echo -n 'db-password' > ./db-password.txt echo -n 'postgres-user-password' > ./postgres-password.txt echo -n 'secret-key' | sha256sum | awk '{ printf $1 }' > ./secret-key.txt Delete the default secrets file 15-secrets.yaml and generate the K8s secret from your files. kubectl create secret generic recipes \\ --from-file=postgresql-password=./db-password.txt \\ --from-file=postgresql-postgres-password=./postgres-password.txt \\ --from-file=secret-key=./secret-key.txt 20-service-account.yml Creating service account recipes for deployment and stateful set. 30-pvc.yaml The creation of the persistent volume claims for media and static content. May you want to increase the size. This expects to have a storage class installed. 40-sts-postgresql.yaml The PostgreSQL stateful set, based on a bitnami image. It runs a init container as root to do the preparations. The postgres container itself runs as a lower privileged user. The recipes app uses the database super user (postgres) as the recipes app is doing some db migrations on startup, which needs super user privileges. 45-service-db.yaml Creating the database service. 50-deployment.yaml The deployment first fires up a init container to do the database migrations and file modifications. This init container runs as root. The init container runs part of the boot.sh script from the vabene1111/recipes image. The deployment then runs two containers, the recipes-nginx and the recipes container which runs the gunicorn app. The nginx container gets it's nginx.conf via config map to deliver static content /static and /media . The guincorn container gets it's secret key and the database password from the secret recipes . gunicorn runs as user nobody . 60-service.yaml Creating the app service. 70-ingress.yaml Setting up the ingress for the recipes service. Requests for static content /static and /media are send to the nginx container, everything else to gunicorn. TLS setup via cert-manager is prepared. You have to change the host from recipes.local to your specific domain. Conclusion All in all: The database is set up as a stateful set. The database container runs as a low privileged user. Database and application use secrets. The application also runs as a low privileged user. nginx runs as root but forks children with a low privileged user. There's an ingress rule to access the application from outside. I tried the setup with kind and it runs well on my local cluster. There is a warning, when you check your system as super user: Media Serving Warning Serving media files directly using gunicorn/python is not recommend! Please follow the steps described here to update your installation. I don't know how this check works, but this warning is simply wrong! ;-) Media and static files are routed by ingress to the nginx container - I promise :-) Updates These manifests are tested against Release 1.0.1. Newer versions may not work without changes. Apply the manifets To apply the manifest with kubectl, use the following command: kubectl apply -f ./docs/install/k8s/","title":"Kubernetes"},{"location":"install/kubernetes/#k8s-setup","text":"This is a setup which should be sufficient for production use. Be sure to replace the default secrets!","title":"K8s Setup"},{"location":"install/kubernetes/#files","text":"","title":"Files"},{"location":"install/kubernetes/#10-configmapyaml","text":"The nginx config map. This is loaded as nginx.conf in the nginx sidecar to configure nginx to deliver static content.","title":"10-configmap.yaml"},{"location":"install/kubernetes/#15-secretsyaml","text":"Contains secrets Replace them! This file is only here for a quick start. Be aware that changing secrets after installation will be messy and is not documented here. You should set new secrets before the installation. As you are reading this document before the installation ;-) Create your own postgresql passwords and the secret key for the django app. See also Managing Secrets using kubectl Replace db-password , postgres-user-password and secret-key with something - well - secret :-) echo -n 'db-password' > ./db-password.txt echo -n 'postgres-user-password' > ./postgres-password.txt echo -n 'secret-key' | sha256sum | awk '{ printf $1 }' > ./secret-key.txt Delete the default secrets file 15-secrets.yaml and generate the K8s secret from your files. kubectl create secret generic recipes \\ --from-file=postgresql-password=./db-password.txt \\ --from-file=postgresql-postgres-password=./postgres-password.txt \\ --from-file=secret-key=./secret-key.txt","title":"15-secrets.yaml"},{"location":"install/kubernetes/#20-service-accountyml","text":"Creating service account recipes for deployment and stateful set.","title":"20-service-account.yml"},{"location":"install/kubernetes/#30-pvcyaml","text":"The creation of the persistent volume claims for media and static content. May you want to increase the size. This expects to have a storage class installed.","title":"30-pvc.yaml"},{"location":"install/kubernetes/#40-sts-postgresqlyaml","text":"The PostgreSQL stateful set, based on a bitnami image. It runs a init container as root to do the preparations. The postgres container itself runs as a lower privileged user. The recipes app uses the database super user (postgres) as the recipes app is doing some db migrations on startup, which needs super user privileges.","title":"40-sts-postgresql.yaml"},{"location":"install/kubernetes/#45-service-dbyaml","text":"Creating the database service.","title":"45-service-db.yaml"},{"location":"install/kubernetes/#50-deploymentyaml","text":"The deployment first fires up a init container to do the database migrations and file modifications. This init container runs as root. The init container runs part of the boot.sh script from the vabene1111/recipes image. The deployment then runs two containers, the recipes-nginx and the recipes container which runs the gunicorn app. The nginx container gets it's nginx.conf via config map to deliver static content /static and /media . The guincorn container gets it's secret key and the database password from the secret recipes . gunicorn runs as user nobody .","title":"50-deployment.yaml"},{"location":"install/kubernetes/#60-serviceyaml","text":"Creating the app service.","title":"60-service.yaml"},{"location":"install/kubernetes/#70-ingressyaml","text":"Setting up the ingress for the recipes service. Requests for static content /static and /media are send to the nginx container, everything else to gunicorn. TLS setup via cert-manager is prepared. You have to change the host from recipes.local to your specific domain.","title":"70-ingress.yaml"},{"location":"install/kubernetes/#conclusion","text":"All in all: The database is set up as a stateful set. The database container runs as a low privileged user. Database and application use secrets. The application also runs as a low privileged user. nginx runs as root but forks children with a low privileged user. There's an ingress rule to access the application from outside. I tried the setup with kind and it runs well on my local cluster. There is a warning, when you check your system as super user: Media Serving Warning Serving media files directly using gunicorn/python is not recommend! Please follow the steps described here to update your installation. I don't know how this check works, but this warning is simply wrong! ;-) Media and static files are routed by ingress to the nginx container - I promise :-)","title":"Conclusion"},{"location":"install/kubernetes/#updates","text":"These manifests are tested against Release 1.0.1. Newer versions may not work without changes.","title":"Updates"},{"location":"install/kubernetes/#apply-the-manifets","text":"To apply the manifest with kubectl, use the following command: kubectl apply -f ./docs/install/k8s/","title":"Apply the manifets"},{"location":"install/kubesail/","text":"Community Contributed This guide was contributed by the community and is neither officially supported, nor updated or tested. KubeSail lets you install Tandoor by providing a simple web interface for installing and managing apps. You can connect any server running Kubernetes, or get a pre-configured PiBox . The KubeSail template is closely based on the Kubernetes installation configs Quick Start Load the Tandoor Recipes template, and click Launch Template . If you have not yet attached your server to KubeSail, see the Getting a Cluster section on the KubeSail docs. Important notes In the \"Template Variables\" section you will see two input fields. These should show RANDOM(16) , indicating they will be randomly generated and specific to your install when you launch the template. If you prefer to set these yourself, you can type them in before launching the template.","title":"KubeSail or PiBox"},{"location":"install/kubesail/#quick-start","text":"Load the Tandoor Recipes template, and click Launch Template . If you have not yet attached your server to KubeSail, see the Getting a Cluster section on the KubeSail docs.","title":"Quick Start"},{"location":"install/kubesail/#important-notes","text":"In the \"Template Variables\" section you will see two input fields. These should show RANDOM(16) , indicating they will be randomly generated and specific to your install when you launch the template. If you prefer to set these yourself, you can type them in before launching the template.","title":"Important notes"},{"location":"install/manual/","text":"Manual installation instructions These instructions are inspired from a standard django/gunicorn/postgresql instructions ( for example ) Warning Be sure to use python 3.9 at least and pip related to python 3.9 at least. Depending on your distribution calling python or pip will use python2 instead of python 3.9. As of writing this documentation 3.10 is available as well. Make sure your machine got at least 2048 MB memory, otherwise the yarn build will fail with FATAL ERROR: Reached heap limit Allocation failed - JavaScript heap out of memory . Prerequisites Setup user: sudo useradd recipes Update the repositories and upgrade your OS: sudo apt update && sudo apt upgrade -y Install all prerequisits sudo apt install -y git curl python3 python3-pip python3-venv nginx Get the last version from the repository: git clone https://github.com/vabene1111/recipes.git -b master Move it to the /var/www directory: mv recipes /var/www Change to the directory: cd /var/www/recipes Give the user permissions: chown -R recipes:www-data /var/www/recipes Create virtual env: python3 -m venv /var/www/recipes Install Javascript Tools (nodejs >= 12 required) ### Just use one of these possibilites! # Using Ubuntu curl -fsSL https://deb.nodesource.com/setup_lts.x | sudo -E bash - sudo apt install -y nodejs # Using Debian, as root curl -fsSL https://deb.nodesource.com/setup_lts.x | bash - apt install -y nodejs # Using a RPM based distro ## ... as root curl -fsSL https://rpm.nodesource.com/setup_lts.x | bash - ## ... no root privileges curl -fsSL https://rpm.nodesource.com/setup_lts.x | sudo bash - sudo npm install --global yarn NodeJS installation issues If you run into problems with the NodeJS installation, please refer to the official documentation . Install postgresql requirements sudo apt install -y libpq-dev postgresql Install LDAP requirements sudo apt install -y libsasl2-dev python3-dev libldap2-dev libssl-dev Install project requirements Update Dependencies change with most updates so the following steps need to be re-run with every update or else the application might stop working. See section Updating below. Using binaries from the virtual env: /var/www/recipes/bin/pip3 install -r requirements.txt You will also need to install front end requirements and build them. For this navigate to the ./vue folder and run cd ./vue yarn install yarn build Setup postgresql sudo -u postgres psql In the psql console: CREATE DATABASE djangodb ; CREATE USER djangouser WITH PASSWORD 'password' ; GRANT ALL PRIVILEGES ON DATABASE djangodb TO djangouser ; ALTER DATABASE djangodb OWNER TO djangouser ; --Maybe not necessary, but should be faster: ALTER ROLE djangouser SET client_encoding TO 'utf8' ; ALTER ROLE djangouser SET default_transaction_isolation TO 'read committed' ; ALTER ROLE djangouser SET timezone TO 'UTC' ; --Grant superuser right to your new user, it will be removed later ALTER USER djangouser WITH SUPERUSER ; --exit Postgres Environment exit Download the .env configuration file and edit it accordingly . wget https://raw.githubusercontent.com/vabene1111/recipes/develop/.env.template -O /var/www/recipes/.env Things to edit: SECRET_KEY : use something secure (generate it with base64 /dev/urandom | head -c50 f.e.). POSTGRES_HOST : probably 127.0.0.1. POSTGRES_PASSWORD : the password we set earlier when setting up djangodb. STATIC_URL , MEDIA_URL : these will be in /var/www/recipes , under /staticfiles/ and /mediafiles/ respectively. Initialize the application Execute export $(cat /var/www/recipes/.env |grep \"^[^#]\" | xargs) to load variables from /var/www/recipes/.env Execute bin/python3 manage.py migrate and revert superuser from postgres: sudo -u postgres psql` and `ALTER USER djangouser WITH NOSUPERUSER; exit Generate static files: bin/python3 manage.py collectstatic --no-input and bin/python3 manage.py collectstatic_js_reverse and remember the folder where files have been copied. Setup web services gunicorn Create a service that will start gunicorn at boot: sudo nano /etc/systemd/system/gunicorn_recipes.service And enter these lines: [Unit] Description=gunicorn daemon for recipes After=network.target [Service] Type=simple Restart=always RestartSec=3 User=recipes Group=www-data WorkingDirectory=/var/www/recipes EnvironmentFile=/var/www/recipes/.env ExecStart=/var/www/recipes/bin/gunicorn --error-logfile /tmp/gunicorn_err.log --log-level debug --capture-output --bind unix:/var/www/recipes/recipes.sock recipes.wsgi:application [Install] WantedBy=multi-user.target Note : -error-logfile /tmp/gunicorn_err.log --log-level debug --capture-output are useful for debugging and can be removed later Note2 : Fix the path in the ExecStart line to where you gunicorn and recipes are Finally, run sudo systemctl enable --now gunicorn_recipes . You can check that the service is correctly started with systemctl status gunicorn_recipes nginx Now we tell nginx to listen to a new port and forward that to gunicorn. sudo nano /etc/nginx/conf.d/recipes.conf And enter these lines: server { listen 8002 ; #access_log /var/log/nginx/access.log; #error_log /var/log/nginx/error.log; # serve media files location /static { alias /var/www/recipes/staticfiles ; } location /media { alias /var/www/recipes/mediafiles ; } location / { proxy_set_header Host $http_host ; proxy_pass http://unix:/var/www/recipes/recipes.sock ; proxy_set_header X-Forwarded-Proto $scheme ; } } Note : Enter the correct path in static and proxy_pass lines. Reload nginx : sudo systemctl reload nginx Updating In order to update the application you will need to run the following commands (probably best to put them into a small script). # change directory cd /var/www/recipes # Update source files git pull # load envirtonment variables export $( cat /var/www/recipes/.env | grep \"^[^#]\" | xargs ) #install project requirements bin/pip3 install -r requirements.txt # migrate database bin/python3 manage.py migrate # collect static files # if the output is not \"0 static files copied\" you might want to run the commands again to make sure everythig is collected bin/python3 manage.py collectstatic --no-input bin/python3 manage.py collectstatic_js_reverse # change to frontend directory cd vue # install and build frontend yarn install yarn build # restart gunicorn service sudo systemctl restart gunicorn_recipes","title":"Manual"},{"location":"install/manual/#manual-installation-instructions","text":"These instructions are inspired from a standard django/gunicorn/postgresql instructions ( for example ) Warning Be sure to use python 3.9 at least and pip related to python 3.9 at least. Depending on your distribution calling python or pip will use python2 instead of python 3.9. As of writing this documentation 3.10 is available as well. Make sure your machine got at least 2048 MB memory, otherwise the yarn build will fail with FATAL ERROR: Reached heap limit Allocation failed - JavaScript heap out of memory .","title":"Manual installation instructions"},{"location":"install/manual/#prerequisites","text":"Setup user: sudo useradd recipes Update the repositories and upgrade your OS: sudo apt update && sudo apt upgrade -y Install all prerequisits sudo apt install -y git curl python3 python3-pip python3-venv nginx Get the last version from the repository: git clone https://github.com/vabene1111/recipes.git -b master Move it to the /var/www directory: mv recipes /var/www Change to the directory: cd /var/www/recipes Give the user permissions: chown -R recipes:www-data /var/www/recipes Create virtual env: python3 -m venv /var/www/recipes Install Javascript Tools (nodejs >= 12 required) ### Just use one of these possibilites! # Using Ubuntu curl -fsSL https://deb.nodesource.com/setup_lts.x | sudo -E bash - sudo apt install -y nodejs # Using Debian, as root curl -fsSL https://deb.nodesource.com/setup_lts.x | bash - apt install -y nodejs # Using a RPM based distro ## ... as root curl -fsSL https://rpm.nodesource.com/setup_lts.x | bash - ## ... no root privileges curl -fsSL https://rpm.nodesource.com/setup_lts.x | sudo bash - sudo npm install --global yarn NodeJS installation issues If you run into problems with the NodeJS installation, please refer to the official documentation .","title":"Prerequisites"},{"location":"install/manual/#install-postgresql-requirements","text":"sudo apt install -y libpq-dev postgresql","title":"Install postgresql requirements"},{"location":"install/manual/#install-ldap-requirements","text":"sudo apt install -y libsasl2-dev python3-dev libldap2-dev libssl-dev","title":"Install LDAP requirements"},{"location":"install/manual/#install-project-requirements","text":"Update Dependencies change with most updates so the following steps need to be re-run with every update or else the application might stop working. See section Updating below. Using binaries from the virtual env: /var/www/recipes/bin/pip3 install -r requirements.txt You will also need to install front end requirements and build them. For this navigate to the ./vue folder and run cd ./vue yarn install yarn build","title":"Install project requirements"},{"location":"install/manual/#setup-postgresql","text":"sudo -u postgres psql In the psql console: CREATE DATABASE djangodb ; CREATE USER djangouser WITH PASSWORD 'password' ; GRANT ALL PRIVILEGES ON DATABASE djangodb TO djangouser ; ALTER DATABASE djangodb OWNER TO djangouser ; --Maybe not necessary, but should be faster: ALTER ROLE djangouser SET client_encoding TO 'utf8' ; ALTER ROLE djangouser SET default_transaction_isolation TO 'read committed' ; ALTER ROLE djangouser SET timezone TO 'UTC' ; --Grant superuser right to your new user, it will be removed later ALTER USER djangouser WITH SUPERUSER ; --exit Postgres Environment exit Download the .env configuration file and edit it accordingly . wget https://raw.githubusercontent.com/vabene1111/recipes/develop/.env.template -O /var/www/recipes/.env Things to edit: SECRET_KEY : use something secure (generate it with base64 /dev/urandom | head -c50 f.e.). POSTGRES_HOST : probably 127.0.0.1. POSTGRES_PASSWORD : the password we set earlier when setting up djangodb. STATIC_URL , MEDIA_URL : these will be in /var/www/recipes , under /staticfiles/ and /mediafiles/ respectively.","title":"Setup postgresql"},{"location":"install/manual/#initialize-the-application","text":"Execute export $(cat /var/www/recipes/.env |grep \"^[^#]\" | xargs) to load variables from /var/www/recipes/.env Execute bin/python3 manage.py migrate and revert superuser from postgres: sudo -u postgres psql` and `ALTER USER djangouser WITH NOSUPERUSER; exit Generate static files: bin/python3 manage.py collectstatic --no-input and bin/python3 manage.py collectstatic_js_reverse and remember the folder where files have been copied.","title":"Initialize the application"},{"location":"install/manual/#setup-web-services","text":"","title":"Setup web services"},{"location":"install/manual/#gunicorn","text":"Create a service that will start gunicorn at boot: sudo nano /etc/systemd/system/gunicorn_recipes.service And enter these lines: [Unit] Description=gunicorn daemon for recipes After=network.target [Service] Type=simple Restart=always RestartSec=3 User=recipes Group=www-data WorkingDirectory=/var/www/recipes EnvironmentFile=/var/www/recipes/.env ExecStart=/var/www/recipes/bin/gunicorn --error-logfile /tmp/gunicorn_err.log --log-level debug --capture-output --bind unix:/var/www/recipes/recipes.sock recipes.wsgi:application [Install] WantedBy=multi-user.target Note : -error-logfile /tmp/gunicorn_err.log --log-level debug --capture-output are useful for debugging and can be removed later Note2 : Fix the path in the ExecStart line to where you gunicorn and recipes are Finally, run sudo systemctl enable --now gunicorn_recipes . You can check that the service is correctly started with systemctl status gunicorn_recipes","title":"gunicorn"},{"location":"install/manual/#nginx","text":"Now we tell nginx to listen to a new port and forward that to gunicorn. sudo nano /etc/nginx/conf.d/recipes.conf And enter these lines: server { listen 8002 ; #access_log /var/log/nginx/access.log; #error_log /var/log/nginx/error.log; # serve media files location /static { alias /var/www/recipes/staticfiles ; } location /media { alias /var/www/recipes/mediafiles ; } location / { proxy_set_header Host $http_host ; proxy_pass http://unix:/var/www/recipes/recipes.sock ; proxy_set_header X-Forwarded-Proto $scheme ; } } Note : Enter the correct path in static and proxy_pass lines. Reload nginx : sudo systemctl reload nginx","title":"nginx"},{"location":"install/manual/#updating","text":"In order to update the application you will need to run the following commands (probably best to put them into a small script). # change directory cd /var/www/recipes # Update source files git pull # load envirtonment variables export $( cat /var/www/recipes/.env | grep \"^[^#]\" | xargs ) #install project requirements bin/pip3 install -r requirements.txt # migrate database bin/python3 manage.py migrate # collect static files # if the output is not \"0 static files copied\" you might want to run the commands again to make sure everythig is collected bin/python3 manage.py collectstatic --no-input bin/python3 manage.py collectstatic_js_reverse # change to frontend directory cd vue # install and build frontend yarn install yarn build # restart gunicorn service sudo systemctl restart gunicorn_recipes","title":"Updating"},{"location":"install/other/","text":"Community Contributed The examples in this section were contributed by members of the community. This page especially contains some setups that might help you if you really want to go down a certain path but none of the examples are supported (as I simply am not able to give you support for them). Apache + Traefik + Sub-Path This guide was contributes by incaseoftrouble in Issue #266 My setup is docker-compose / traefik / apache / recipes. Swapping out apache for nginx should be straightforward. Relevant parts: docker-compose: apache : # omitting other config volumes : - ./recipes/static:/var/www/recipes/static:ro - ./recipes/media:/var/www/recipes/media:ro labels : traefik.enable : true traefik.http.routers.apache-recipes.rule : Host(`<host>`) && PathPrefix(`/<www path>`) traefik.http.routers.apache-recipes.entrypoints : http traefik.http.routers.apache-recipes.service : apache traefik.http.services.apache.loadbalancer.server.port : 80 traefik.http.services.apache.loadbalancer.server.scheme : http ... recipes : volumes : - ./recipes/static:/opt/recipes/staticfiles:rw - ./recipes/media:/opt/recipes/mediafiles:rw environment : # all the other env - SCRIPT_NAME=/<sub path> - JS_REVERSE_SCRIPT_PREFIX=/<sub path>/ - STATIC_URL=/<www path>/static/ - MEDIA_URL=/<www path>/media/ labels : traefik.enable : true traefik.http.routers.recipes.rule : Host(`<host>`) && PathPrefix(`/<sub path>`) traefik.http.routers.recipes.entrypoints : http traefik.http.services.recipes.loadbalancer.server.port : 8080 traefik.http.services.recipes.loadbalancer.server.scheme : http apache: Alias /<www path>/static/ /var/www/recipes/static/ Alias /<www path>/media/ /var/www/recipes/media/ <Directory \"/var/www/recipes/\"> Require all granted </Directory> I used two paths <sub path> and <www path> for simplicity. In my case I have <sub path> = recipes and <www path> = serve/recipes . One could also change the matching rules of traefik to have everything under one path. I left out the TLS config in this example for simplicity. WSL If you want to install Tandoor on the Windows Subsystem for Linux you can find a detailed post herre https://github.com/TandoorRecipes/recipes/issues/1733","title":"Other setups"},{"location":"install/other/#apache-traefik-sub-path","text":"This guide was contributes by incaseoftrouble in Issue #266 My setup is docker-compose / traefik / apache / recipes. Swapping out apache for nginx should be straightforward. Relevant parts: docker-compose: apache : # omitting other config volumes : - ./recipes/static:/var/www/recipes/static:ro - ./recipes/media:/var/www/recipes/media:ro labels : traefik.enable : true traefik.http.routers.apache-recipes.rule : Host(`<host>`) && PathPrefix(`/<www path>`) traefik.http.routers.apache-recipes.entrypoints : http traefik.http.routers.apache-recipes.service : apache traefik.http.services.apache.loadbalancer.server.port : 80 traefik.http.services.apache.loadbalancer.server.scheme : http ... recipes : volumes : - ./recipes/static:/opt/recipes/staticfiles:rw - ./recipes/media:/opt/recipes/mediafiles:rw environment : # all the other env - SCRIPT_NAME=/<sub path> - JS_REVERSE_SCRIPT_PREFIX=/<sub path>/ - STATIC_URL=/<www path>/static/ - MEDIA_URL=/<www path>/media/ labels : traefik.enable : true traefik.http.routers.recipes.rule : Host(`<host>`) && PathPrefix(`/<sub path>`) traefik.http.routers.recipes.entrypoints : http traefik.http.services.recipes.loadbalancer.server.port : 8080 traefik.http.services.recipes.loadbalancer.server.scheme : http apache: Alias /<www path>/static/ /var/www/recipes/static/ Alias /<www path>/media/ /var/www/recipes/media/ <Directory \"/var/www/recipes/\"> Require all granted </Directory> I used two paths <sub path> and <www path> for simplicity. In my case I have <sub path> = recipes and <www path> = serve/recipes . One could also change the matching rules of traefik to have everything under one path. I left out the TLS config in this example for simplicity.","title":"Apache + Traefik + Sub-Path"},{"location":"install/other/#wsl","text":"If you want to install Tandoor on the Windows Subsystem for Linux you can find a detailed post herre https://github.com/TandoorRecipes/recipes/issues/1733","title":"WSL"},{"location":"install/swag/","text":"Danger Please refer to the official documentation for the container setup. This example shows just one setup that may or may not differ from yours in significant ways. This tutorial does not cover security measures, backups, and many other things that you might want to consider. Prerequisites You have a newly spun-up Ubuntu server with docker (pre-)installed. At least one mydomain.com and one mysubdomain.mydomain.com are pointing to the server's IP. (This tutorial does not cover subfolder installation.) You have an ssh terminal session open. Installation Download and edit Tandoor configuration cd /opt mkdir recipes cd recipes wget https://raw.githubusercontent.com/vabene1111/recipes/develop/.env.template -O .env base64 /dev/urandom | head -c50 Copy the response from that last command and paste the key into the .env file: nano .env You'll also need to enter a Postgres password into the .env file. Then, save the file and exit the editor. Install and configure Docker Compose In keeping with these instructions : cd /opt curl -L --fail https://raw.githubusercontent.com/linuxserver/docker-docker-compose/master/run.sh -o /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose Next, create and edit the docker compose file. nano docker-compose.yml Paste the following and adjust your domains, subdomains and time zone. --- version: \"2.1\" services: swag: image: ghcr.io/linuxserver/swag container_name: swag cap_add: - NET_ADMIN environment: - PUID=1000 - PGID=1000 - TZ=Europe/Berlin # <---- EDIT THIS <---- <---- - URL=mydomain.com # <---- EDIT THIS <---- <---- - SUBDOMAINS=mysubdomain,myothersubdomain # <---- EDIT THIS <---- <---- - EXTRA_DOMAINS=myotherdomain.com # <---- EDIT THIS <---- <---- - VALIDATION=http volumes: - ./swag:/config - ./recipes/media:/media ports: - 443:443 - 80:80 restart: unless-stopped db_recipes: restart: always container_name: db_recipes image: postgres:11-alpine volumes: - ./recipes/db:/var/lib/postgresql/data env_file: - ./recipes/.env recipes: image: vabene1111/recipes container_name: recipes restart: unless-stopped env_file: - ./recipes/.env environment: - UID=1000 - GID=1000 - TZ=Europe/Berlin # <---- EDIT THIS <---- <---- volumes: - ./recipes/static:/opt/recipes/staticfiles - ./recipes/media:/opt/recipes/mediafiles depends_on: - db_recipes Save and exit. Create containers and configure swag reverse proxy docker-compose up -d cd /opt/swag/nginx/proxy-confs cp recipes.subdomain.conf.sample recipes.subdomain.conf nano recipes.subdomain.conf Change the line server_name recipes.*; to server_name mysubdomain.*; , save and exit. Finalize cd /opt docker restart swag recipes Go to https://mysubdomain.mydomain.com . (If you get a \"502 Bad Gateway\" error, be patient. It might take a short while until it's functional.)","title":"Swag"},{"location":"install/swag/#prerequisites","text":"You have a newly spun-up Ubuntu server with docker (pre-)installed. At least one mydomain.com and one mysubdomain.mydomain.com are pointing to the server's IP. (This tutorial does not cover subfolder installation.) You have an ssh terminal session open.","title":"Prerequisites"},{"location":"install/swag/#installation","text":"","title":"Installation"},{"location":"install/swag/#download-and-edit-tandoor-configuration","text":"cd /opt mkdir recipes cd recipes wget https://raw.githubusercontent.com/vabene1111/recipes/develop/.env.template -O .env base64 /dev/urandom | head -c50 Copy the response from that last command and paste the key into the .env file: nano .env You'll also need to enter a Postgres password into the .env file. Then, save the file and exit the editor.","title":"Download and edit Tandoor configuration"},{"location":"install/swag/#install-and-configure-docker-compose","text":"In keeping with these instructions : cd /opt curl -L --fail https://raw.githubusercontent.com/linuxserver/docker-docker-compose/master/run.sh -o /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose Next, create and edit the docker compose file. nano docker-compose.yml Paste the following and adjust your domains, subdomains and time zone. --- version: \"2.1\" services: swag: image: ghcr.io/linuxserver/swag container_name: swag cap_add: - NET_ADMIN environment: - PUID=1000 - PGID=1000 - TZ=Europe/Berlin # <---- EDIT THIS <---- <---- - URL=mydomain.com # <---- EDIT THIS <---- <---- - SUBDOMAINS=mysubdomain,myothersubdomain # <---- EDIT THIS <---- <---- - EXTRA_DOMAINS=myotherdomain.com # <---- EDIT THIS <---- <---- - VALIDATION=http volumes: - ./swag:/config - ./recipes/media:/media ports: - 443:443 - 80:80 restart: unless-stopped db_recipes: restart: always container_name: db_recipes image: postgres:11-alpine volumes: - ./recipes/db:/var/lib/postgresql/data env_file: - ./recipes/.env recipes: image: vabene1111/recipes container_name: recipes restart: unless-stopped env_file: - ./recipes/.env environment: - UID=1000 - GID=1000 - TZ=Europe/Berlin # <---- EDIT THIS <---- <---- volumes: - ./recipes/static:/opt/recipes/staticfiles - ./recipes/media:/opt/recipes/mediafiles depends_on: - db_recipes Save and exit.","title":"Install and configure Docker Compose"},{"location":"install/swag/#create-containers-and-configure-swag-reverse-proxy","text":"docker-compose up -d cd /opt/swag/nginx/proxy-confs cp recipes.subdomain.conf.sample recipes.subdomain.conf nano recipes.subdomain.conf Change the line server_name recipes.*; to server_name mysubdomain.*; , save and exit.","title":"Create containers and configure swag reverse proxy"},{"location":"install/swag/#finalize","text":"cd /opt docker restart swag recipes Go to https://mysubdomain.mydomain.com . (If you get a \"502 Bad Gateway\" error, be patient. It might take a short while until it's functional.)","title":"Finalize"},{"location":"install/synology/","text":"Community Contributed This guide was contributed by the community and is neither officially supported, nor updated or tested. Many people appear to host this application on their Synology NAS. The following documentation was provided by @therealschimmi in this issue discussion . There is also this ( word , pdf ) awesome and very detailed guide provided by @DiversityBug. There are, as always, most likely other ways to do this but this can be used as a starting point for your setup. Since I cannot test it myself feedback and improvements are always very welcome. Instructions Basic guide to setup vabenee1111/recipes docker container on Synology NAS. 1. Login to Synology DSM through your browser Install Docker through package center Optional: Create a shared folder for your docker projects, they have to store data somewhere outside the containers Create a folder somewhere, I suggest naming it 'recipes' and storing it in the dedicated docker folder Within, create the necessary folder structure. You will need these folders: 2. Download templates Info vabene1111 gives you a few samples for various setups to work with. I chose to use the plain setup for now. Open https://github.com/vabene1111/recipes/tree/develop/docs/install/docker ( link ) Download docker-compose.yml to your recipes folder ( direct link to plain ) Open https://github.com/vabene1111/recipes/tree/develop/nginx/conf.d ( link ) Download Recipes.conf to your conf.d folder ( direct link ) Open https://github.com/vabene1111/recipes/blob/develop/.env.template ( link ) Copy the text and save it as .env to your recipes folder (no filename extension!) Add a POSTGRES_PASSWORD Once done, it should look like this: 3. Edit docker-compose.yml Open docker-compose.yml in a text editor This file tells docker how to setup recipes. Docker will create three containers for recipes to work, recipes, nginx and postgresql. They are all required and need to store and share data through the folders you created before. Edit line 26, this line specifies which external synology port will point to which internal docker port. Chose a free port to use and replace the first number with it. You will open recipes by browsing to http://your.synology.ip:chosen.port, e.g. http://192.168.1.1:2000 If you want to use port 2000 you would edit to 2000:80 4. SSH into your Synology You need to access your Synology through SSH Execute following commands ssh root@your.synology.ip connect to your synology. root password is the same as admin password, sometimes root access is not possible for whatever reason, then replace root with admin cd /volume1/docker/recipes access the folder where you store docker-compose.yml docker-compose up -d this starts your containers according to your docker-compose.yml. if you logged in with admin you will have to use sudo docker-compose up -d instead, it will ask for the admin password again. This output tells you all 3 containers have been setup ... Creating recipes_nginx_recipes_1 ... done Creating recipes_db_recipes_1 ... done Creating recipes_web_recipes_1 ... done Browse to 192.168.1.1:2000 or whatever your IP and port are While the containers are starting and doing whatever they need to do, you might still get HTTP errors e.g. 500 or 502. Just be patient and try again in a moment 5. Firewall You need to set up firewall rules in order for the recipes_web container to be able to connect to the recipes_db container. Control Panel -> Security -> Firewall -> Edit Rules -> Create Ports: All Source IP: Specific IP -> Select -> Subnet insert docker network ip (can be found in the docker application, network tab) Example: IP address: 172.18.0.0 and Subnet mask/Prefix length: 255.255.255.0 Action: Allow Save and make sure it's above the deny rules 6. Additional SSL Setup Easiest way is to do it via Reverse Proxy. Control Panel -> Login Portal (renamed Since DSM 7, previously Application Portal) -> Advanced -> Reverse Proxy Create insert name Source: Protocol: HTTPS Hostname: URL if you access from outside, otherwise ip in network Port: The port you want to access, has to be a different one that the one in the docker-compose file HSTS can be enabled Destination: Protocol: HTTP Hostname: localhost Port: port in docker-compose file Click on Custom Header and press Create -> Websocket Save Control Panel -> Security -> Firewall -> Edit Rules -> Create Ports: Select form a list of built-in applications -> Select -> You find your Reverse Proxy, enable it Source IP: Depends, All allows access from outside, i use specific to only connect in my network Action: Allow Save and make sure it's above the deny rules [Deprecated, Note: ssl Path changed for DSM 7] 6.1 Additional SSL Setup - create folder ssl inside nginx folder - download your ssl certificate from security tab in dsm control panel - or create a task in task manager because Synology will update the certificate every few months - set task to repeat every day - in the script write: SRC=\"/usr/syno/etc/certificate/system/default\" DEST=\"/volume1/docker/recipes/nginx/ssl/\" if [ ! -f \"$DEST/fullchain.pem\" ] || [ \"$SRC/fullchain.pem\" -nt \"$DEST/fullchain.pem\" ]; then cp \"$SRC/fullchain.pem\" \"$DEST/\" cp \"$SRC/privkey.pem\" \"$DEST/\" chown root:root \"$DEST/fullchain.pem\" \"$DEST/privkey.pem\" chmod 600 \"$DEST/fullchain.pem\" \"$DEST/privkey.pem\" /usr/syno/bin/synowebapi --exec api=SYNO.Docker.Container version=1 method=restart name=recipes_nginx_recipes_1 fi - change docker-compose.yml add - ./nginx/ssl:/etc/nginx/certs to the volumes of nginx_recipes","title":"Synology"},{"location":"install/synology/#instructions","text":"Basic guide to setup vabenee1111/recipes docker container on Synology NAS.","title":"Instructions"},{"location":"install/synology/#1-login-to-synology-dsm-through-your-browser","text":"Install Docker through package center Optional: Create a shared folder for your docker projects, they have to store data somewhere outside the containers Create a folder somewhere, I suggest naming it 'recipes' and storing it in the dedicated docker folder Within, create the necessary folder structure. You will need these folders:","title":"1. Login to Synology DSM through your browser"},{"location":"install/synology/#2-download-templates","text":"Info vabene1111 gives you a few samples for various setups to work with. I chose to use the plain setup for now. Open https://github.com/vabene1111/recipes/tree/develop/docs/install/docker ( link ) Download docker-compose.yml to your recipes folder ( direct link to plain ) Open https://github.com/vabene1111/recipes/tree/develop/nginx/conf.d ( link ) Download Recipes.conf to your conf.d folder ( direct link ) Open https://github.com/vabene1111/recipes/blob/develop/.env.template ( link ) Copy the text and save it as .env to your recipes folder (no filename extension!) Add a POSTGRES_PASSWORD Once done, it should look like this:","title":"2. Download templates"},{"location":"install/synology/#3-edit-docker-composeyml","text":"Open docker-compose.yml in a text editor This file tells docker how to setup recipes. Docker will create three containers for recipes to work, recipes, nginx and postgresql. They are all required and need to store and share data through the folders you created before. Edit line 26, this line specifies which external synology port will point to which internal docker port. Chose a free port to use and replace the first number with it. You will open recipes by browsing to http://your.synology.ip:chosen.port, e.g. http://192.168.1.1:2000 If you want to use port 2000 you would edit to 2000:80","title":"3. Edit docker-compose.yml"},{"location":"install/synology/#4-ssh-into-your-synology","text":"You need to access your Synology through SSH Execute following commands ssh root@your.synology.ip connect to your synology. root password is the same as admin password, sometimes root access is not possible for whatever reason, then replace root with admin cd /volume1/docker/recipes access the folder where you store docker-compose.yml docker-compose up -d this starts your containers according to your docker-compose.yml. if you logged in with admin you will have to use sudo docker-compose up -d instead, it will ask for the admin password again. This output tells you all 3 containers have been setup ... Creating recipes_nginx_recipes_1 ... done Creating recipes_db_recipes_1 ... done Creating recipes_web_recipes_1 ... done Browse to 192.168.1.1:2000 or whatever your IP and port are While the containers are starting and doing whatever they need to do, you might still get HTTP errors e.g. 500 or 502. Just be patient and try again in a moment","title":"4. SSH into your Synology"},{"location":"install/synology/#5-firewall","text":"You need to set up firewall rules in order for the recipes_web container to be able to connect to the recipes_db container. Control Panel -> Security -> Firewall -> Edit Rules -> Create Ports: All Source IP: Specific IP -> Select -> Subnet insert docker network ip (can be found in the docker application, network tab) Example: IP address: 172.18.0.0 and Subnet mask/Prefix length: 255.255.255.0 Action: Allow Save and make sure it's above the deny rules","title":"5. Firewall"},{"location":"install/synology/#6-additional-ssl-setup","text":"Easiest way is to do it via Reverse Proxy. Control Panel -> Login Portal (renamed Since DSM 7, previously Application Portal) -> Advanced -> Reverse Proxy Create insert name Source: Protocol: HTTPS Hostname: URL if you access from outside, otherwise ip in network Port: The port you want to access, has to be a different one that the one in the docker-compose file HSTS can be enabled Destination: Protocol: HTTP Hostname: localhost Port: port in docker-compose file Click on Custom Header and press Create -> Websocket Save Control Panel -> Security -> Firewall -> Edit Rules -> Create Ports: Select form a list of built-in applications -> Select -> You find your Reverse Proxy, enable it Source IP: Depends, All allows access from outside, i use specific to only connect in my network Action: Allow Save and make sure it's above the deny rules [Deprecated, Note: ssl Path changed for DSM 7] 6.1 Additional SSL Setup - create folder ssl inside nginx folder - download your ssl certificate from security tab in dsm control panel - or create a task in task manager because Synology will update the certificate every few months - set task to repeat every day - in the script write: SRC=\"/usr/syno/etc/certificate/system/default\" DEST=\"/volume1/docker/recipes/nginx/ssl/\" if [ ! -f \"$DEST/fullchain.pem\" ] || [ \"$SRC/fullchain.pem\" -nt \"$DEST/fullchain.pem\" ]; then cp \"$SRC/fullchain.pem\" \"$DEST/\" cp \"$SRC/privkey.pem\" \"$DEST/\" chown root:root \"$DEST/fullchain.pem\" \"$DEST/privkey.pem\" chmod 600 \"$DEST/fullchain.pem\" \"$DEST/privkey.pem\" /usr/syno/bin/synowebapi --exec api=SYNO.Docker.Container version=1 method=restart name=recipes_nginx_recipes_1 fi - change docker-compose.yml add - ./nginx/ssl:/etc/nginx/certs to the volumes of nginx_recipes","title":"6. Additional SSL Setup"},{"location":"install/traefik/","text":"Danger Please refer to the official documentation . This example just shows something similar to my setup in case you dont understand the official documentation. You need to create a network called traefik using docker network create traefik . docker-compose.yml version: \"3.3\" services: traefik: image: \"traefik:v2.1\" container_name: \"traefik\" ports: - \"443:443\" - \"80:80\" - \"8080:8080\" volumes: - \"./letsencrypt:/letsencrypt\" - \"/var/run/docker.sock:/var/run/docker.sock:ro\" - \"./config:/etc/traefik/\" networks: default: external: name: traefik traefik.toml Place this in a directory called config as this is mounted into the traefik container (see docer compose). Change the email address accordingly . [api] insecure=true [providers.docker] endpoint = \"unix:///var/run/docker.sock\" exposedByDefault = false network = \"traefik\" #[log] # level = \"DEBUG\" [entryPoints] [entryPoints.web] address = \":80\" [entryPoints.web_secure] address = \":443\" [certificatesResolvers.le_resolver.acme] email = \"you_email@mail.com\" storage = \"/letsencrypt/acme.json\" tlsChallenge=true","title":"Traefik"},{"location":"install/traefik/#docker-composeyml","text":"version: \"3.3\" services: traefik: image: \"traefik:v2.1\" container_name: \"traefik\" ports: - \"443:443\" - \"80:80\" - \"8080:8080\" volumes: - \"./letsencrypt:/letsencrypt\" - \"/var/run/docker.sock:/var/run/docker.sock:ro\" - \"./config:/etc/traefik/\" networks: default: external: name: traefik","title":"docker-compose.yml"},{"location":"install/traefik/#traefiktoml","text":"Place this in a directory called config as this is mounted into the traefik container (see docer compose). Change the email address accordingly . [api] insecure=true [providers.docker] endpoint = \"unix:///var/run/docker.sock\" exposedByDefault = false network = \"traefik\" #[log] # level = \"DEBUG\" [entryPoints] [entryPoints.web] address = \":80\" [entryPoints.web_secure] address = \":443\" [certificatesResolvers.le_resolver.acme] email = \"you_email@mail.com\" storage = \"/letsencrypt/acme.json\" tlsChallenge=true","title":"traefik.toml"},{"location":"install/unraid/","text":"Community Contributed This guide was contributed by the community and is neither officially supported, nor updated or tested. Unraid is an operating system that allows you to easily install and setup applications. Thanks to CorneliousJD this application can easily be installed using unraid. Please view Issue #184 for further details. There is also a discussion thread on the unraid forum where he gives additional information. Installation Install Community Applications Tandoor for unRAID is available via Community Applications . You will first need to install Community Applications (CA) by following the directions here: Unraid forums Locate and install Tandoor Recipes After that, you can go to the \"Apps\" tab in unRAID and search for Tandoor Recipes , locate the correct container and install it. Configure settings The default settings should be fine for most users, just be sure to enter a secret key that is randomly generated. Then click Apply . Access website After the container is installed, click on the Tandoor Recipes icon and click the WebUI button to launch the web user interface. Set the container to auto-start if you wish.","title":"Unraid"},{"location":"install/unraid/#installation","text":"","title":"Installation"},{"location":"install/unraid/#install-community-applications","text":"Tandoor for unRAID is available via Community Applications . You will first need to install Community Applications (CA) by following the directions here: Unraid forums","title":"Install Community Applications"},{"location":"install/unraid/#locate-and-install-tandoor-recipes","text":"After that, you can go to the \"Apps\" tab in unRAID and search for Tandoor Recipes , locate the correct container and install it.","title":"Locate and install Tandoor Recipes"},{"location":"install/unraid/#configure-settings","text":"The default settings should be fine for most users, just be sure to enter a secret key that is randomly generated. Then click Apply .","title":"Configure settings"},{"location":"install/unraid/#access-website","text":"After the container is installed, click on the Tandoor Recipes icon and click the WebUI button to launch the web user interface. Set the container to auto-start if you wish.","title":"Access website"},{"location":"system/backup/","text":"There is currently no \"good\" way of backing up your data implemented in the application itself. This mean that you will be responsible for backing up your data. It is planned to add a \"real\" backup feature similar to applications like homeassistant where a snapshot can be downloaded and restored through the web interface. Warning When developing a new backup strategy, make sure to also test the restore process! Database Please use any standard way of backing up your database. For most systems this can be achieved by using a dump command that will create an SQL file with all the required data. Please refer to your Database System documentation. I personally use a little script that I have created to automatically pull SQL dumps from a postgresql database. It is neither well tested nor documented so use at your own risk. I would recommend using it only as a starting place for your own backup strategy. Mediafiles The only Data this application stores apart from the database are the media files (e.g. images) used in your recipes. They can be found in the mediafiles mounted directory (depending on your installation). To create a backup of those files simply copy them elsewhere. Do it the other way around for restoring. The filenames consist of <random uuid4>_<recipe_id> . In case you screw up really badly this can help restore data. Manual backup from docker build The standard docker build of tandoor uses postgresql as the back end database. This can be backed up using a function called \"dumpall\". This generates a .SQL file containing a list of commands for a postgresql server to use to rebuild your database. You will also need to back up the media files separately. Making a full copy of the docker directory can work as a back up, but only if you know you will be using the same hardware, os, and postgresql version upon restore. If not, then the different version of postgresql won't be compatible with the existing tables. You can back up from docker even when the tandoor container is failing, so long as the postgresql database has started successfully. When using this backup method, ensure that your recipes have imported successfully. One user reported only the titles and images importing on first try, requiring a second run of the import command. the following commands assume that your docker-compose files are in a folder called \"docker\". replace \"docker_db_recipes_1\" with the name of your db container. The commands also assume you use a backup name of pgdump.sql. It's a good idea to include a date in this filename, so that successive backups do not get deleted. To back up: sudo docker exec -t docker_db_recipes_1 pg_dumpall -U djangouser > pgdump.sql To restore: cat pgdump.sql | sudo docker exec -i docker_db_recipes_1 psql postgres -U djangouser This connects to the postgres table instead of the actual dgangodb table, as the import function needs to delete the table, which can't be dropped off you're connected to it. Backup using export and import You can now export recipes from Tandoor using the export function. This method requires a working web interface. 1. Click on a recipe 2. Click on the three meatballs then export 3. Select the all recipes toggle and then export. This should download a zip file. Import: Go to Import > from app > tandoor and select the zip file you want to import from.","title":"Backup"},{"location":"system/backup/#database","text":"Please use any standard way of backing up your database. For most systems this can be achieved by using a dump command that will create an SQL file with all the required data. Please refer to your Database System documentation. I personally use a little script that I have created to automatically pull SQL dumps from a postgresql database. It is neither well tested nor documented so use at your own risk. I would recommend using it only as a starting place for your own backup strategy.","title":"Database"},{"location":"system/backup/#mediafiles","text":"The only Data this application stores apart from the database are the media files (e.g. images) used in your recipes. They can be found in the mediafiles mounted directory (depending on your installation). To create a backup of those files simply copy them elsewhere. Do it the other way around for restoring. The filenames consist of <random uuid4>_<recipe_id> . In case you screw up really badly this can help restore data.","title":"Mediafiles"},{"location":"system/backup/#manual-backup-from-docker-build","text":"The standard docker build of tandoor uses postgresql as the back end database. This can be backed up using a function called \"dumpall\". This generates a .SQL file containing a list of commands for a postgresql server to use to rebuild your database. You will also need to back up the media files separately. Making a full copy of the docker directory can work as a back up, but only if you know you will be using the same hardware, os, and postgresql version upon restore. If not, then the different version of postgresql won't be compatible with the existing tables. You can back up from docker even when the tandoor container is failing, so long as the postgresql database has started successfully. When using this backup method, ensure that your recipes have imported successfully. One user reported only the titles and images importing on first try, requiring a second run of the import command. the following commands assume that your docker-compose files are in a folder called \"docker\". replace \"docker_db_recipes_1\" with the name of your db container. The commands also assume you use a backup name of pgdump.sql. It's a good idea to include a date in this filename, so that successive backups do not get deleted. To back up: sudo docker exec -t docker_db_recipes_1 pg_dumpall -U djangouser > pgdump.sql To restore: cat pgdump.sql | sudo docker exec -i docker_db_recipes_1 psql postgres -U djangouser This connects to the postgres table instead of the actual dgangodb table, as the import function needs to delete the table, which can't be dropped off you're connected to it.","title":"Manual backup from docker build"},{"location":"system/backup/#backup-using-export-and-import","text":"You can now export recipes from Tandoor using the export function. This method requires a working web interface. 1. Click on a recipe 2. Click on the three meatballs then export 3. Select the all recipes toggle and then export. This should download a zip file. Import: Go to Import > from app > tandoor and select the zip file you want to import from.","title":"Backup using export and import"},{"location":"system/migration_sqlite-postgres/","text":"How to migrate from sqlite3 database to postgresql This migration was written while using the unraid template (docker) for TandoorRecipes, version 1.3.0. While some commands are unraid specific, it should in general work for any setup. Make a backup of your /mnt/user/appdata/recipes dir. Without changing any settings, get a shell into the TandoorRecipes docker through the Web-UI or by running docker exec -it TandoorRecipes /bin/sh cd /opt/recipes ./venv/bin/python manage.py export -a > /data/dump.json Create a Postgresql database (With a new user & database for recipes) I used the postgresql14 template. psql -U postgres postgres=# create database tandoor; postgres=# create user tandoor with encrypted password 'yoursupersecretpassworddontusethisone'; postgres=# grant all privileges on database tandoor to tandoor; Now its time to change some enviourment variables in TandoorRecipes template: DB_ENGINE=django.db.backends.postgresql # Database Engine, previous value: `django.db.backends.sqlite3` POSTGRES_HOST=<Your unraid host ip> # PostgreSQL Host POSTGRES_PORT=5432 # PostgreSQL Host POSTGRES_USER=tandoor # PostgreSQL User POSTGRES_PASSWORD=yoursupersecretpassworddyoudidntcopy # PostgreSQL Password POSTGRES_DB=tandoor # Database, previous value: `/data/recipes.db` Save it, and start the container once. It will perform all database migrations once for the postgresql database. Get a shell into the docker through the WEB-UI or by running docker exec -it TandoorRecipes /bin/sh cd /opt/recipes ./venv/bin/python manage.py import /data/dump.json Enjoy your new fuzzy search options and SLIGHTLY performance increase!","title":"How to migrate from sqlite3 database to postgresql"},{"location":"system/migration_sqlite-postgres/#how-to-migrate-from-sqlite3-database-to-postgresql","text":"This migration was written while using the unraid template (docker) for TandoorRecipes, version 1.3.0. While some commands are unraid specific, it should in general work for any setup. Make a backup of your /mnt/user/appdata/recipes dir. Without changing any settings, get a shell into the TandoorRecipes docker through the Web-UI or by running docker exec -it TandoorRecipes /bin/sh cd /opt/recipes ./venv/bin/python manage.py export -a > /data/dump.json Create a Postgresql database (With a new user & database for recipes) I used the postgresql14 template. psql -U postgres postgres=# create database tandoor; postgres=# create user tandoor with encrypted password 'yoursupersecretpassworddontusethisone'; postgres=# grant all privileges on database tandoor to tandoor; Now its time to change some enviourment variables in TandoorRecipes template: DB_ENGINE=django.db.backends.postgresql # Database Engine, previous value: `django.db.backends.sqlite3` POSTGRES_HOST=<Your unraid host ip> # PostgreSQL Host POSTGRES_PORT=5432 # PostgreSQL Host POSTGRES_USER=tandoor # PostgreSQL User POSTGRES_PASSWORD=yoursupersecretpassworddyoudidntcopy # PostgreSQL Password POSTGRES_DB=tandoor # Database, previous value: `/data/recipes.db` Save it, and start the container once. It will perform all database migrations once for the postgresql database. Get a shell into the docker through the WEB-UI or by running docker exec -it TandoorRecipes /bin/sh cd /opt/recipes ./venv/bin/python manage.py import /data/dump.json Enjoy your new fuzzy search options and SLIGHTLY performance increase!","title":"How to migrate from sqlite3 database to postgresql"},{"location":"system/permissions/","text":"WIP This application was developed for private use in a trusted environment. Due to popular demand a basic permission system has been added. It does its job protecting the most critical parts of the application, but it is not yet recommended to give accounts to completely untrusted users. Work is done to improve the permission system, but it's not yet fully done and tested. Permission levels The following table roughly defines the capabilities of each role Group Capabilities logged in user Can do almost nothing without a group. guest - Search and view recipes - write comments - change user settings (e.g. language, theme, password) user Can do basically everything except for what admins can do admin - Create, edit and delete external storage - Create, edit and delete synced paths django superuser Ignores all permission checks and can access admin interface Creating User accounts Warning Users without groups cannot do anything. Make sure to assign them a group! You can either create new users through the admin interface or by sending them invite links. Invite links can be generated on the System page. If you specify a username during the creation of the link the person using it won't be able to change that name. Managing Permissions Management of permissions can currently only be achieved through the django admin interface. Warning Please do not rename the groups as this breaks the permission system.","title":"Permission System"},{"location":"system/permissions/#permission-levels","text":"The following table roughly defines the capabilities of each role Group Capabilities logged in user Can do almost nothing without a group. guest - Search and view recipes - write comments - change user settings (e.g. language, theme, password) user Can do basically everything except for what admins can do admin - Create, edit and delete external storage - Create, edit and delete synced paths django superuser Ignores all permission checks and can access admin interface","title":"Permission levels"},{"location":"system/permissions/#creating-user-accounts","text":"Warning Users without groups cannot do anything. Make sure to assign them a group! You can either create new users through the admin interface or by sending them invite links. Invite links can be generated on the System page. If you specify a username during the creation of the link the person using it won't be able to change that name.","title":"Creating User accounts"},{"location":"system/permissions/#managing-permissions","text":"Management of permissions can currently only be achieved through the django admin interface. Warning Please do not rename the groups as this breaks the permission system.","title":"Managing Permissions"},{"location":"system/updating/","text":"The Updating process depends on your chosen method of installation While intermediate updates can be skipped when updating please make sure to read the release notes in case some special action is required to update. Docker For all setups using Docker the updating process look something like this Before updating it is recommended to create a backup ! Stop the container using docker-compose down Pull the latest image using docker-compose pull Start the container again using docker-compose up -d Manual For all setups using a manual installation updates usually involve downloading the latest source code from GitHub. After that make sure to run: manage.py collectstatic manage.py migrate To apply all new migrations and collect new static files.","title":"Updating"},{"location":"system/updating/#docker","text":"For all setups using Docker the updating process look something like this Before updating it is recommended to create a backup ! Stop the container using docker-compose down Pull the latest image using docker-compose pull Start the container again using docker-compose up -d","title":"Docker"},{"location":"system/updating/#manual","text":"For all setups using a manual installation updates usually involve downloading the latest source code from GitHub. After that make sure to run: manage.py collectstatic manage.py migrate To apply all new migrations and collect new static files.","title":"Manual"}]}